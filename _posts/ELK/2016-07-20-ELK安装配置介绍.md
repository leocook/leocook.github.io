---
layout: post
comments: true
date: 2016-07-20
categories: ELK
tags: es logstash kibana ELK
---

* content
{:toc}

es是接触的比较早，在13年就做过相关开发，后来使用过ELK来做一些数据统计。最近打算从头来梳理一下这块的东西，今天就先从安装和配置开始吧。




## 版本列表

| project  | version |
| --- | --- |
| es | 2.3.4 |
| logstash | 2.3.4 |
| kibana | 4.5.3 |

## 1.logstash配置

### 1.1.Jdk安装
http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html


### 1.2.下载logstash
https://www.elastic.co/downloads/logstash

### 1.3.启动

解压后可直接启动，不增加额外的配置也是能够启动成功的。启动方式有多种，这里举例说明。

- 使用-e指定启动的参数

```
./logstash -e 'input { stdin { } } output { stdout {} }'
```

这里设定stdin为输入，stdout为输出。

- 使用配置文件启动

```
cat logstash-simple.conf
input { stdin { } }
output {
   stdout { codec=> rubydebug }
}

./logstash agent -f logstash-simple.conf
```

### 1.4.验证

启动后才命令行输入"hello World"，如下：

```
root@dt-vt-153:/opt/logstash/logstash-2.3.4/bin# ./logstash agent -f logstash-simple.conf

Settings: Default pipeline workers: 1
Pipeline main started
hello World
{
       "message" => "hello World",
       "@version" => "1",
       "@timestamp" => "2016-07-18T07:20:20.526Z",
       "host" => "0.0.0.0"
}
```

打印出来的message部分显示为输入内容。

## 2.ES

### 2.1.下载
https://www.elastic.co/downloads/elasticsearch

### 2.2.配置
配置一下主机的地址,这里不配置的话，只能在安装服务的宿主机上使用localhost来访问ES了。

```
vi config/elasticsearch.yml
network.host: 0.0.0.0
```

### 2.3.启动

```
/opt/elasticsearch/elasticsearch-2.3.4/bin/elasticsearch
```

### 2.4.插件安装

kopf插件安装：

```
/opt/elasticsearch/elasticsearch-2.3.4/bin/plugin install lmenezes/elasticsearch-kopf
```

安装完之后，可以访问web页面http://[hostname]:9200/_plugin/kopf查看。

### 2.5.验证

es默认使用的9200端口，可使用下面的命令来查看该端口是否已经被监听：

```
netstat -anp |grep :9200
```

或者使用浏览器访问端口9200.


## 3. Kibana

### 3.1.下载
https://www.elastic.co/downloads/kibana

### 3.2.配置

配置一下es的地址。

```
vi config/kibana.yml

elasticsearch.url: "http://[hostname]:9200"
```

这里默认是使用ES的数据。

### 3.3.启动

```
/opt/kibana/kibana-4.5.3-linux-x64/bin/kibana
```

### 3.4.验证

访问：

```
http://[hostname]:5601/
```
点击"create"创建索引名称。

## 4.使ELK整体协作起来

### 4.1.原理

- logstash

logstash主要用作收集数据使用，可以自由的定义数据的入口和出口，兼容多种数据源。

- elasticsearch

es和solr比较类似，都是基于lucene的来提供的搜索服务。但是在高并发的表现上，ES的负载均衡效果是优于solr的。

- kibana

kibana是一个可以可以用来查看ES里数据的Web。在早期logstash有一个logstash-web，但是功能比较简单。咱们这里说的kibana严格意义上说是kibana4，是在2015年重构完成的一个版本。

### 4.2.E和L的连接
其实就是把logstash收集到的数据写入es中，这里只要在logstash的启动参数上做配置就可以了，具体的配置文件如下：

```
vi logstash-indexer.conf

input {
  file {
    type =>"syslog"
    path => [ "/var/log/syslog" ]
  }
  syslog {
    type =>"syslog"
    port =>"5544"
  }
}
output {
  stdout { codec=> rubydebug }
  elasticsearch {hosts => "localhost" }
}
```

- 配置介绍

logstash的配置里，一定要有一个input和一个output。
file: 这里配置输入的文件信息。
syslog：把logstash配置为一个可接收syslog服务器来接收file里变化的数据。
output里定义了两处输出，分别是**stdout**命令行和**elasticsearch**。

- 启动

```
nohup ./logstash agent -f logstash-indexer.conf > nohup &
```

### 4.3.Kibana的配置
只需要修改kibana.yml中es的地址就可以了。


### 4.4.ES
ES在这个架构中作为数据存储和索引的系统。无额外的特殊配置。

### 5.小结
ELK架构在处理运维系统的日志分析以及一些数据量不是很大的场景还是很实用的。快速、简单、易扩展，企业中使用可以考虑使用hdfs作为es的数据存储来使用，具体性能需要根据实际的业务复杂度来衡量，复杂度不是很高的海量数据统计，可优先考虑使用elk方案。

参考地址：
http://baidu.blog.51cto.com/71938/1676798
https://www.gitbook.com/book/chenryn/kibana-guide-cn/details


