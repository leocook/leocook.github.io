<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>leocook</title>
    <description></description>
    <link>http://leocook.github.io/</link>
    <atom:link href="http://leocook.github.io/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Mon, 05 Jun 2017 23:45:03 +0800</pubDate>
    <lastBuildDate>Mon, 05 Jun 2017 23:45:03 +0800</lastBuildDate>
    <generator>Jekyll v3.2.1</generator>
    
      <item>
        <title>Jcf（java集合框架）概括</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#section&quot; id=&quot;markdown-toc-section&quot;&gt;1.概述&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#iterator&quot; id=&quot;markdown-toc-iterator&quot;&gt;2.Iterator接口&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#collection&quot; id=&quot;markdown-toc-collection&quot;&gt;3.Collection&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#list&quot; id=&quot;markdown-toc-list&quot;&gt;3.1.List&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#set&quot; id=&quot;markdown-toc-set&quot;&gt;3.2.Set&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#queue&quot; id=&quot;markdown-toc-queue&quot;&gt;3.3.Queue&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#map&quot; id=&quot;markdown-toc-map&quot;&gt;4.Map&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#hashmap&quot; id=&quot;markdown-toc-hashmap&quot;&gt;4.1.HashMap&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#linkedhashmap&quot; id=&quot;markdown-toc-linkedhashmap&quot;&gt;4.2.LinkedHashMap&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#treemap&quot; id=&quot;markdown-toc-treemap&quot;&gt;4.3.TreeMap&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-1&quot; id=&quot;markdown-toc-section-1&quot;&gt;5.其它集合&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#vector&quot; id=&quot;markdown-toc-vector&quot;&gt;5.1.Vector&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#stack&quot; id=&quot;markdown-toc-stack&quot;&gt;5.2.Stack&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#hashtable&quot; id=&quot;markdown-toc-hashtable&quot;&gt;5.3.HashTable&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-2&quot; id=&quot;markdown-toc-section-2&quot;&gt;6.总结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在Java中，集合也就是可以装载多个&lt;strong&gt;Java对象&lt;/strong&gt;的某种对象，所以Java的集合只能装载对象，在装载基础数据类型的时候，事实上装载的是基础类型锁对应的包装类。&lt;/p&gt;

&lt;p&gt;在学习JCF之前，我们先回顾一下，在计算机编程中我们期望&lt;strong&gt;集合能有哪些能力？&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;可以遍历集合全部的元素&lt;/li&gt;
  &lt;li&gt;关于集合类部元素的顺序
    &lt;ul&gt;
      &lt;li&gt;保留写入集合的顺序&lt;/li&gt;
      &lt;li&gt;可根据元素的大小自动排序&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;能快速查找出集合中的某个元素&lt;/li&gt;
  &lt;li&gt;可以根据位置来快速的修改元素&lt;/li&gt;
  &lt;li&gt;能高效的增加、删除集合中元素&lt;/li&gt;
  &lt;li&gt;集合内的元素可以快速去重&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;聊到集合，那肯定少不了下面几种基础的数据结构：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;线性存储
    &lt;ul&gt;
      &lt;li&gt;（可变）数组&lt;/li&gt;
      &lt;li&gt;链表&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Hash散列表&lt;/li&gt;
  &lt;li&gt;平衡树&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section&quot;&gt;1.概述&lt;/h2&gt;

&lt;p&gt;在Java2.0之前，只有一些简单的集合，例如Vector/Stack/Hashtable，由于这些集合直接使用synchronized关键字来实现线程安全，使得这些集合在使用的时候效率极低。从Java2.0开始之后，Java提供了一系列的Java Collections Framework（JCF）。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://7xriy2.com1.z0.glb.clouddn.com/JCF.gif&quot; alt=&quot;JCF&quot; /&gt;&lt;/p&gt;

&lt;p&gt;下面开始讲讲Java的集合框架（后面简称JCF）。JCF主要包括了两种类型的集合：&lt;strong&gt;Collection&lt;/strong&gt;和&lt;strong&gt;Map&lt;/strong&gt;。
Collection集合中的每个节点存放的是一个元素。Map集合中的每个元素存放的是&amp;lt;key,value&amp;gt;型的键值对。&lt;/p&gt;

&lt;h2 id=&quot;iterator&quot;&gt;2.Iterator接口&lt;/h2&gt;

&lt;p&gt;这是迭代器接口，不同集合的Iterator实现会不一样。例如ArrayList的Iterator实现是内部类Itr。
集合实现了Iterator之后，就可以使用迭代器顺序遍历了。
Iterator接口的定义如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Object next()：返回迭代器刚越过的元素的引用，返回值是Object，需要强制转换成自己需要的类型

boolean hasNext()：判断容器内是否还有可供访问的元素

void remove()：删除迭代器刚越过的元素
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;查看源码的话，会看到下面这一段代码：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; ......
 * @see Collection
 * @see ListIterator
 * @see Iterable
 public interface Iterator&amp;lt;E&amp;gt; {
 ......
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Iterable&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;所有实现了Iterable接口的集合，都可以使用增强的for循环，因为这个集合将会实现一个自己的Iterator。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ListIterator&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ListIterator是针对List实现的迭代器。由于List是顺序存储结构，所以除了next()、hasNext()、remove()方法，ListIterator还提供了List下标处理的相关方法，例如获取上/下一个元素以及它们的下标情况。&lt;/p&gt;

&lt;h2 id=&quot;collection&quot;&gt;3.Collection&lt;/h2&gt;

&lt;p&gt;Collection是Java集合层次结构中的根节点，实现Collection的集合中，有的是允许存放重复的元素，有的不允许有重复的元素（set），有的集合是有序的，有的则是无序的。Collection下面有三种子接口，分别是List、Set、Queue，下面逐一介绍。&lt;/p&gt;

&lt;h3 id=&quot;list&quot;&gt;3.1.List&lt;/h3&gt;

&lt;p&gt;实现List接口的集合有着两大特性：允许元素重复、元素是有序的。实现了List接口的集合，可以通过位置来操作集合的元素。下图展示了List接口中的全部方法：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://7xriy2.com1.z0.glb.clouddn.com/list.png&quot; alt=&quot;List&quot; /&gt;&lt;/p&gt;

&lt;p&gt;下面是几个常用的List类型集合。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ArrayList&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;基于数组实现的线性存储集合。数组的大小可以变化，当元素个数超过了数组的大小，将会重新创建一个更大长度的数组，并把当前数组中的内容复制进去，每次长度增长为原来的1.5倍左右，可以查看源码：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private void grow(int minCapacity) {
    // overflow-conscious code
    int oldCapacity = elementData.length;
    int newCapacity = oldCapacity + (oldCapacity &amp;gt;&amp;gt; 1);
    if (newCapacity - minCapacity &amp;lt; 0)
        newCapacity = minCapacity;
    if (newCapacity - MAX_ARRAY_SIZE &amp;gt; 0)
        newCapacity = hugeCapacity(minCapacity);
    // minCapacity is usually close to size, so this is a win:
    elementData = Arrays.copyOf(elementData, newCapacity);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;LinkedList&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;基于链表实现的线性存储集合。下面对比ArrayList和LinkedList：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;操作&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;ArrayList&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;LinkedList&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;内部数据结构&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;数组&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;链表&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;是否顺序结构&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;是&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;是&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;位置检索&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;快&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;慢&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;增、删&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;慢&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;快&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;set&quot;&gt;3.2.Set&lt;/h3&gt;

&lt;p&gt;实现Set接口的集合内部元素不重复，Set有三个具体的实现类：HashSet（散列集）、LinkedHashSet（顺序集）、TreeSet（平衡树）。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;HashSet&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;基于hash的无序set。其实HashSet内部是用HashMap实现的，HashMap后边会说到。在散列集中，有两个名词需要关注，初始容量和客座率。客座率是确定在增加规则集之前，该规则集的饱满程度，当元素个数超过了容量与客座率的乘积时，容量就会自动翻倍。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;LinkedHashSet&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;基于链表实现的HashSet，LinkedHashSet中的元素是有序的，且顺序和写入的顺序一致。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;TreeSet&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;TreeSet是一个有序的Set，排序的比较器可以通过传入Comparator来自定义。&lt;/p&gt;

&lt;h3 id=&quot;queue&quot;&gt;3.3.Queue&lt;/h3&gt;

&lt;p&gt;队列是一种FIFO（First in first out）数据结构，元素在Queue的末尾添加，在头部删除。
&lt;img src=&quot;http://7xriy2.com1.z0.glb.clouddn.com/Queue.png&quot; alt=&quot;Queue&quot; /&gt;
Queue接口分别定义了上面6个方法，分别有插入、移除和检查的功能，有的方法在某些特殊情况下回报错，有的则不会，具体见下表：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Operation&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;抛出异常&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;返回特殊值&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;操作失败的条件&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Insert（插入）&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;add(e)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;offer(e),return false&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;当队列空间有限制，且没有多余的空间时&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Remove（移除）&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;remove()&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;poll(),return null&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;队列为空&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Examine（检查）&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;element()&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;peek(),return null&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;队列为空&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Queue平时用的不是很多，优先队列PriorityQueue有的时候会用到。&lt;/p&gt;

&lt;h2 id=&quot;map&quot;&gt;4.Map&lt;/h2&gt;

&lt;p&gt;Map是存储键值对映射（key,value）的容器类，可以存储任意类型的对象。但是key不能重复，且一个key只能对应一个值。如果使用对象作为key,那么必须要考虑一下该对象类的hashCode方法和equals方法是否需要重写，因为map是用着两个方法来判断key是否相等的，其中hashCode是用来加速判断的，如果hashCode相等，还会用equals方法来判断。&lt;/p&gt;

&lt;p&gt;常用到的Map接口实现类，有三个：HashMap、LinkedHashMap、TreeMap。Map接口定义的方法列表可见下图：
&lt;img src=&quot;http://7xriy2.com1.z0.glb.clouddn.com/map.png&quot; alt=&quot;Map&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;hashmap&quot;&gt;4.1.HashMap&lt;/h3&gt;

&lt;p&gt;HashMap是基于数组+链表实现的Hash散列Map结构，数组里存放着索引，链表里存放的是元素数据。(key,value)键值对中，key的hash值就是数组的下标。&lt;/p&gt;

&lt;p&gt;在Jdk1.8中，对HashMap做了优化，当链表的长度超过8时，链表结构将会变为了平衡树，这样做主要是为了在HashMap里的元素较多时，能够加快查找的速度。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://7xriy2.com1.z0.glb.clouddn.com/map%20struct.png&quot; alt=&quot;map结构&quot; /&gt;&lt;/p&gt;

&lt;p&gt;关于HashMap，其实有很多可以细聊的，它与很多集合都有着关系。后边会再来一篇，详细说一下Java中HashMap的设计，以及Java中散列存储的设计思想。&lt;/p&gt;

&lt;h3 id=&quot;linkedhashmap&quot;&gt;4.2.LinkedHashMap&lt;/h3&gt;

&lt;p&gt;LinkedHashMap类继承了HashMap类，HashMap中的元素是没有顺序的，但是LinkedHashMap中的元素是有顺序的。
LinkedHashMap里的元素顺序有两种排序方式：第一种是根据元素key被插入的顺序;第二种是根据元素被访问的顺序来排序（最近最少被访问的元素优先）。&lt;/p&gt;

&lt;h3 id=&quot;treemap&quot;&gt;4.3.TreeMap&lt;/h3&gt;

&lt;p&gt;TreeMap是基于红黑树结构来实现的，可以使用Comparable或Comparator接口来实现排序的比较算法。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;在日常开发中，如果不用考虑键值对元素的顺序，就使用HashMap；如果需要考虑元素插入顺序，就使用LinkedHashMap；如果需要根据Key自定义排序规则，那么就使用TreeMap。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;section-1&quot;&gt;5.其它集合&lt;/h2&gt;

&lt;p&gt;下面简单说几个不是很常用的集合。&lt;/p&gt;

&lt;h3 id=&quot;vector&quot;&gt;5.1.Vector&lt;/h3&gt;

&lt;p&gt;Vector的使用和ArrayList的使用基本一样，它是线程安全的线程安全，但是Vector的线程安全是使用关键字synchronized修饰实现的，所以Vector的效率很低。相对来说，ArrayList更加高效！&lt;/p&gt;

&lt;h3 id=&quot;stack&quot;&gt;5.2.Stack&lt;/h3&gt;

&lt;p&gt;Stack是Java2之前设计的栈结构，内部是使用数组实现的。我们知道栈结构的操作中会频繁的出现入栈和出栈，那么使用数组结构的话，在栈结构变长时，自然会带来性能上的折扣。
LinkedList也具备栈的功能，而且是基于链表实现的，所以在开发需要用到栈结构时，推荐使用LinkedList。&lt;/p&gt;

&lt;h3 id=&quot;hashtable&quot;&gt;5.3.HashTable&lt;/h3&gt;

&lt;p&gt;HashTable的功能和HashMap相似，它是Dictionary类的，并且使用了synchronized关键字实现了线程安全，所以性能会很差！
除此之外，HashTable的Key不能为空指针null,但是HashMap的key可以为null。&lt;/p&gt;

&lt;p&gt;关于集合的线程安全，后边会另写一篇详细说明。&lt;/p&gt;

&lt;p&gt;参考地址：
http://www.open-open.com/lib/view/open1474167415464.html
http://www.cnblogs.com/CarpenterLee/p/5414253.html&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;6.总结&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;JCF接口架构&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;http://7xriy2.com1.z0.glb.clouddn.com/JCF.gif&quot; alt=&quot;JCF接口架构&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;常用的集合分类情况&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;http://7xriy2.com1.z0.glb.clouddn.com/jcf%E4%BD%BF%E7%94%A8.png&quot; alt=&quot;常用的集合分类情况&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;接口功能实现&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下面表格描述的比较好，每个接口对应不同数据结构的实现。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://7xriy2.com1.z0.glb.clouddn.com/jcf%20imp.png&quot; alt=&quot;JCF 接口实现&quot; /&gt;&lt;/p&gt;

&lt;p&gt;参考文档：
http://docs.oracle.com/javase/6/docs/technotes/guides/collections/overview.html
http://www.jianshu.com/p/63e76826e852&lt;/p&gt;
</description>
        <pubDate>Mon, 05 Jun 2017 00:00:00 +0800</pubDate>
        <link>http://leocook.github.io/2017/06/05/JCF-Java%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6-%E6%A6%82%E6%8B%AC/</link>
        <guid isPermaLink="true">http://leocook.github.io/2017/06/05/JCF-Java%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6-%E6%A6%82%E6%8B%AC/</guid>
        
        <category>java</category>
        
        
        <category>java</category>
        
      </item>
    
      <item>
        <title>Scipy生态系统初探</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#scipy&quot; id=&quot;markdown-toc-scipy&quot;&gt;1.SciPy技术栈的安装&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#numpyscipy&quot; id=&quot;markdown-toc-numpyscipy&quot;&gt;2.NumPy&amp;amp;scipy测试&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#matplotlib&quot; id=&quot;markdown-toc-matplotlib&quot;&gt;2.Matplotlib测试&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#ipython&quot; id=&quot;markdown-toc-ipython&quot;&gt;3.IPython&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#scipy-1&quot; id=&quot;markdown-toc-scipy-1&quot;&gt;4.关于SciPy技术栈的发行版&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#anaconda&quot; id=&quot;markdown-toc-anaconda&quot;&gt;5.使用Anaconda管理软件包&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#theano&quot; id=&quot;markdown-toc-theano&quot;&gt;5.1. 安装Theano&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#tensorflow&quot; id=&quot;markdown-toc-tensorflow&quot;&gt;5.2 安装Tensorflow&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;SciPy是一个基于Python的开源生态系统，也称为&lt;code&gt;SciPy技术栈&lt;/code&gt;，主要为数学计算、科学研究以及工程计算提供服务。&lt;/p&gt;

&lt;p&gt;Anaconda则是SciPy技术栈的发行版，它解决了SciPy技术栈各个组件之间的兼容、以及管理工作。
&lt;img src=&quot;http://7xriy2.com1.z0.glb.clouddn.com/SciPy%20stack.png&quot; alt=&quot;SciPy stack&quot; title=&quot;SciPy stack&quot; /&gt;&lt;/p&gt;

&lt;p&gt;下面是SciPy生态圈中一些常用的包：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;NumPy&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;NumPy是Python科学计算中的一个比较基础的包，它主要有下面几项功能：&lt;/p&gt;

&lt;p&gt;a.强大的矩阵计算能力&lt;/p&gt;

&lt;p&gt;b.用于整合C/C++和Fortran代码的工具包&lt;/p&gt;

&lt;p&gt;c.比较成熟的（广播）函数库&lt;/p&gt;

&lt;p&gt;d.支持线性代数求解、傅里叶变换，以及随机数处理&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;SciPy library&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;SciPy是组成SciPy技术栈的核心包之一，它的相关API使用起来都比较友好，且执行效率高。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Matplotlib&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Matplotlib是一个基于Python的2D绘图库，能绘制出出版社级别的高质量图。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;IPython&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;一个功能强大的Python命令行，也是Jupyter的内核。
关于Jupyter，被人们广为熟知的有Jupyter Notebook，之前的名字叫IPython Notebook，是一个交互式笔记本，可以运行几十种语言。在Jupyter Notebook中，代码可以实时的生成图像、视频等。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Sympy&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;基于Python的符号计算包。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;pandas&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;pandas提供一些高效、易用的数据结构，以及数据分析工具。&lt;/p&gt;

&lt;h2 id=&quot;scipy&quot;&gt;1.SciPy技术栈的安装&lt;/h2&gt;

&lt;p&gt;直接使用pip安装&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip install --user numpy scipy matplotlib ipython jupyter pandas sympy nose
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;numpyscipy&quot;&gt;2.NumPy&amp;amp;scipy测试&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; import numpy as np
&amp;gt;&amp;gt;&amp;gt; a = np.arange(15).reshape(3, 5)
&amp;gt;&amp;gt;&amp;gt; a
array([[ 0,  1,  2,  3,  4],
       [ 5,  6,  7,  8,  9],
       [10, 11, 12, 13, 14]])
&amp;gt;&amp;gt;&amp;gt; a.shape
(3, 5)
&amp;gt;&amp;gt;&amp;gt; a.ndim
2
&amp;gt;&amp;gt;&amp;gt; a.dtype.name
'int64'
&amp;gt;&amp;gt;&amp;gt; a.itemsize
8
&amp;gt;&amp;gt;&amp;gt; a.size
15
&amp;gt;&amp;gt;&amp;gt; type(a)
&amp;lt;type 'numpy.ndarray'&amp;gt;
&amp;gt;&amp;gt;&amp;gt; b = np.array([6, 7, 8])
&amp;gt;&amp;gt;&amp;gt; b
array([6, 7, 8])
&amp;gt;&amp;gt;&amp;gt; type(b)
&amp;lt;type 'numpy.ndarray'&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ python
&amp;gt;&amp;gt;&amp;gt; import numpy as np
&amp;gt;&amp;gt;&amp;gt; np.test('full')
&amp;gt;&amp;gt;&amp;gt; import scipy
&amp;gt;&amp;gt;&amp;gt; scipy.test()
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;matplotlib&quot;&gt;2.Matplotlib测试&lt;/h2&gt;

&lt;p&gt;关于matplotlib的例子，在http://matplotlib.org/examples/index.html这里有很多，下面随机选了两个运行一下作为例子让大家看下。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;animate_decay&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;python animate_decay.py
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;http://7xriy2.com1.z0.glb.clouddn.com/animate_decay.gif&quot; alt=&quot;animate_decay&quot; title=&quot;animate_decay&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;dynamic_image&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;python dynamic_image.py
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;http://7xriy2.com1.z0.glb.clouddn.com/dynamic_image.gif&quot; alt=&quot;dynamic_image&quot; title=&quot;dynamic_image&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;ipython&quot;&gt;3.IPython&lt;/h2&gt;

&lt;p&gt;直接使用命令ipython进入&lt;/p&gt;

&lt;h2 id=&quot;scipy-1&quot;&gt;4.关于SciPy技术栈的发行版&lt;/h2&gt;

&lt;p&gt;我们知道SciPy技术栈内有很多技术组件，那么不同的组件配合使用时，肯定会有兼容的问题。我们期望能有个工具，它可以帮助我们管理SciPy技术栈的各个组件，保证他们的兼容性，同事也方便我们安装管理。它就是&lt;code&gt;Anaconda&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;可以在这里选择自己的操作系统环境&lt;code&gt;https://www.continuum.io/downloads&lt;/code&gt;.
笔者使用的是macOS，在安装了Anaconda之后，系统的Python环境都变为了Anaconda安装的python了：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;leocookMacBook-Pro:~ leocook$ which python
/Users/wulin/anaconda/bin/python
leocookMacBook-Pro:~ leocook$ whereis python
/usr/bin/python
leocookMacBook-Pro:~ leocook$ python
Python 2.7.13 |Anaconda 4.3.1 (x86_64)| (default, Dec 20 2016, 23:05:08)
[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)] on darwin
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
Anaconda is brought to you by Continuum Analytics.
Please check out: http://continuum.io/thanks and https://anaconda.org
&amp;gt;&amp;gt;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;可以使用Anaconda命令查看我们安装了SciPy技术栈中的哪些组件：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;leocookMacBook-Pro:~ leocook$ conda list
# packages in environment at /Users/leocook/anaconda:
#
_license                  1.1                      py27_1
alabaster                 0.7.9                    py27_0
anaconda                  4.3.1               np111py27_0
anaconda-client           1.6.0                    py27_0
anaconda-navigator        1.5.0                    py27_0
anaconda-project          0.4.1                    py27_0
appdirs                   1.4.3                     &amp;lt;pip&amp;gt;
appnope                   0.1.0                    py27_0
appscript                 1.0.1                    py27_0
argcomplete               1.0.0                    py27_1
astroid                   1.4.9                    py27_0
astropy                   1.3                 np111py27_0
babel                     2.3.4                    py27_0
backports                 1.0                      py27_0
backports_abc             0.5                      py27_0
beautifulsoup4            4.5.3                    py27_0
bitarray                  0.8.1                    py27_0
blaze                     0.10.1                   py27_0
bokeh                     0.12.4                   py27_0
boto                      2.45.0                   py27_0
bottleneck                1.2.0               np111py27_0
cdecimal                  2.3                      py27_2
cffi                      1.9.1                    py27_0
chardet                   2.3.0                    py27_0
chest                     0.2.3                    py27_0
click                     6.7                      py27_0
cloudpickle               0.2.2                    py27_0
clyent                    1.2.2                    py27_0
colorama                  0.3.7                    py27_0
conda                     4.3.17                   py27_0
conda-env                 2.6.0                         0
configobj                 5.0.6                    py27_0
configparser              3.5.0                    py27_0
contextlib2               0.5.4                    py27_0
cryptography              1.7.1                    py27_0
curl                      7.52.1                        0
cycler                    0.10.0                   py27_0
cython                    0.25.2                   py27_0
cytoolz                   0.8.2                    py27_0
dask                      0.13.0                   py27_0
datashape                 0.5.4                    py27_0
decorator                 4.0.11                   py27_0
dill                      0.2.5                    py27_0
docutils                  0.13.1                   py27_0
entrypoints               0.2.2                    py27_0
enum34                    1.1.6                    py27_0
et_xmlfile                1.0.1                    py27_0
fastcache                 1.0.2                    py27_1
flask                     0.12                     py27_0
flask-cors                3.0.2                    py27_0
freetype                  2.5.5                         2
funcsigs                  1.0.2                     &amp;lt;pip&amp;gt;
funcsigs                  1.0.2                    py27_0
functools32               3.2.3.2                  py27_0
futures                   3.0.5                    py27_0
get_terminal_size         1.0.0                    py27_0
gevent                    1.2.1                    py27_0
greenlet                  0.4.11                   py27_0
grin                      1.2.1                    py27_3
h5py                      2.6.0               np111py27_2
hdf5                      1.8.17                        1
heapdict                  1.0.0                    py27_1
icu                       54.1                          0
idna                      2.2                      py27_0
imagesize                 0.7.1                    py27_0
ipaddress                 1.0.18                   py27_0
ipykernel                 4.5.2                    py27_0
ipython                   5.1.0                    py27_1
ipython_genutils          0.1.0                    py27_0
ipywidgets                5.2.2                    py27_1
isort                     4.2.5                    py27_0
itsdangerous              0.24                     py27_0
jbig                      2.1                           0
jdcal                     1.3                      py27_0
jedi                      0.9.0                    py27_1
jinja2                    2.9.4                    py27_0
jpeg                      9b                            0
jsonschema                2.5.1                    py27_0
jupyter                   1.0.0                    py27_3
jupyter_client            4.4.0                    py27_0
jupyter_console           5.0.0                    py27_0
jupyter_core              4.2.1                    py27_0
Keras                     2.0.4                     &amp;lt;pip&amp;gt;
lazy-object-proxy         1.2.2                    py27_0
libgpuarray               0.6.4                         0
libiconv                  1.14                          0
libpng                    1.6.27                        0
libtiff                   4.0.6                         3
libxml2                   2.9.4                         0
libxslt                   1.1.29                        0
llvmlite                  0.15.0                   py27_0
locket                    0.2.0                    py27_1
lxml                      3.7.2                    py27_0
mako                      1.0.6                    py27_0
markupsafe                0.23                     py27_2
matplotlib                2.0.0               np111py27_0
mistune                   0.7.3                    py27_1
mkl                       2017.0.1                      0
mkl-service               1.1.2                    py27_3
mock                      2.0.0                     &amp;lt;pip&amp;gt;
mpmath                    0.19                     py27_1
multipledispatch          0.4.9                    py27_0
nbconvert                 4.2.0                    py27_0
nbformat                  4.2.0                    py27_0
networkx                  1.11                     py27_0
nltk                      3.2.2                    py27_0
nose                      1.3.7                    py27_1
notebook                  4.3.1                    py27_0
numba                     0.30.1              np111py27_0
numexpr                   2.6.1               np111py27_2
numpy                     1.12.1                    &amp;lt;pip&amp;gt;
numpy                     1.11.3                   py27_0
numpydoc                  0.6.0                    py27_0
odo                       0.5.0                    py27_1
openpyxl                  2.4.1                    py27_0
openssl                   1.0.2k                        1
packaging                 16.8                      &amp;lt;pip&amp;gt;
pandas                    0.19.2              np111py27_1
partd                     0.3.7                    py27_0
path.py                   10.0                     py27_0
pathlib2                  2.2.0                    py27_0
patsy                     0.4.1                    py27_0
pbr                       3.0.0                     &amp;lt;pip&amp;gt;
pep8                      1.7.0                    py27_0
pexpect                   4.2.1                    py27_0
pickleshare               0.7.4                    py27_0
pillow                    4.0.0                    py27_0
pip                       9.0.1                    py27_1
ply                       3.9                      py27_0
prompt_toolkit            1.0.9                    py27_0
protobuf                  3.3.0                     &amp;lt;pip&amp;gt;
psutil                    5.0.1                    py27_0
ptyprocess                0.5.1                    py27_0
py                        1.4.32                   py27_0
pyasn1                    0.1.9                    py27_0
pyaudio                   0.2.7                    py27_0
pycosat                   0.6.1                    py27_1
pycparser                 2.17                     py27_0
pycrypto                  2.6.1                    py27_4
pycurl                    7.43.0                   py27_2
pyflakes                  1.5.0                    py27_0
pygments                  2.1.3                    py27_0
pygpu                     0.6.4                    py27_0
pylint                    1.6.4                    py27_1
pyopenssl                 16.2.0                   py27_0
pyparsing                 2.2.0                     &amp;lt;pip&amp;gt;
pyparsing                 2.1.4                    py27_0
pyqt                      5.6.0                    py27_1
pytables                  3.3.0               np111py27_0
pytest                    3.0.5                    py27_0
python                    2.7.13                        0
python-dateutil           2.6.0                    py27_0
python.app                1.2                      py27_4
pytz                      2016.10                  py27_0
pyyaml                    3.12                     py27_0
pyzmq                     16.0.2                   py27_0
qt                        5.6.2                         0
qtawesome                 0.4.3                    py27_0
qtconsole                 4.2.1                    py27_1
qtpy                      1.2.1                    py27_0
readline                  6.2                           2
redis                     3.2.0                         0
redis-py                  2.10.5                   py27_0
requests                  2.12.4                   py27_0
rope                      0.9.4                    py27_1
ruamel_yaml               0.11.14                  py27_1
scandir                   1.4                      py27_0
scikit-image              0.12.3              np111py27_1
scikit-learn              0.18.1              np111py27_1
scipy                     0.18.1              np111py27_1
seaborn                   0.7.1                    py27_0
setuptools                27.2.0                   py27_0
setuptools                35.0.2                    &amp;lt;pip&amp;gt;
simplegeneric             0.8.1                    py27_1
singledispatch            3.4.0.3                  py27_0
sip                       4.18                     py27_0
six                       1.10.0                   py27_0
six                       1.10.0                    &amp;lt;pip&amp;gt;
snowballstemmer           1.2.1                    py27_0
sockjs-tornado            1.0.3                    py27_0
sphinx                    1.5.1                    py27_0
spyder                    3.1.2                    py27_0
sqlalchemy                1.1.5                    py27_0
sqlite                    3.13.0                        0
ssl_match_hostname        3.4.0.2                  py27_1
statsmodels               0.6.1               np111py27_1
subprocess32              3.2.7                    py27_0
sympy                     1.0                      py27_0
tensorflow                1.1.0                     &amp;lt;pip&amp;gt;
terminado                 0.6                      py27_0
theano                    0.9.0                    py27_0
tk                        8.5.18                        0
toolz                     0.8.2                    py27_0
tornado                   4.4.2                    py27_0
traitlets                 4.3.1                    py27_0
unicodecsv                0.14.1                   py27_0
wcwidth                   0.1.7                    py27_0
Werkzeug                  0.12.1                    &amp;lt;pip&amp;gt;
werkzeug                  0.11.15                  py27_0
wheel                     0.29.0                    &amp;lt;pip&amp;gt;
wheel                     0.29.0                   py27_0
widgetsnbextension        1.2.6                    py27_0
wrapt                     1.10.8                   py27_0
xlrd                      1.0.0                    py27_0
xlsxwriter                0.9.6                    py27_0
xlwings                   0.10.2                   py27_0
xlwt                      1.2.0                    py27_0
xz                        5.2.2                         1
yaml                      0.1.6                         0
zlib                      1.2.8                         3
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;anaconda&quot;&gt;5.使用Anaconda管理软件包&lt;/h2&gt;

&lt;h3 id=&quot;theano&quot;&gt;5.1. 安装Theano&lt;/h3&gt;

&lt;p&gt;Theano是一个基于Python的深度学习库。默认Theano是没有被安装的，那么我们下面使用Anaconda来安装它。
首先我们使用命令来查看一下Theano包的情况：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;leocookMacBook-Pro:~ leocook$ conda search theano
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;然后得到：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
Fetching package metadata .........
theano                       0.8.2                    py35_0  defaults
                             0.8.2                    py34_0  defaults
                             0.8.2                    py27_0  defaults
                             0.9.0                    py35_0  defaults
                             0.9.0                    py36_0  defaults
                          *  0.9.0                    py27_0  defaults
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;我们可以看到有多个版面，然后我们直接运行下面的命令：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda install theano
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;它会选择和我们py版本兼容的最新版本&lt;code&gt;0.9.0                    py27_0&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&quot;tensorflow&quot;&gt;5.2 安装Tensorflow&lt;/h3&gt;

&lt;p&gt;Tensorflow是Google开源的一个人工智能学习系统。我们使用&lt;code&gt;conda search tensorflow&lt;/code&gt;命令查看发现Anaconda库中没有Tensorflow的包。&lt;/p&gt;

&lt;p&gt;其实，我们也可以用Anaconda来管理那些使用其他方式安装的包，例如使用pip安装的包。下面简单说明一下使用Anaconda管理使用pip安装的Tensorflow。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;创建一个名称为tensorflow的conda环境&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda create -n tensorflow
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;激活conda环境&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;source activate tensorflow
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;激活环境后，在这里执行命令安装的程序，都会被Anaconda管理。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;使用pip来安装TensorFlow&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在这里&lt;code&gt;https://www.tensorflow.org/install/install_mac#the_url_of_the_tensorflow_python_package&lt;/code&gt;找到对应版本的URL，也就是下面命令中将会使用到的&lt;code&gt;$TF_PYTHON_URL&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(tensorflow)$ pip install --ignore-installed --upgrade $TF_PYTHON_URL
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;例如笔者的是：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.1.0-py2-none-any.whl
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;安装完成后，退出tensorflow这个Anaconda环境：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;source deactivate tensorflow
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

</description>
        <pubDate>Wed, 10 May 2017 00:00:00 +0800</pubDate>
        <link>http://leocook.github.io/2017/05/10/SciPy%E7%94%9F%E6%80%81%E7%B3%BB%E7%BB%9F%E5%88%9D%E6%8E%A2/</link>
        <guid isPermaLink="true">http://leocook.github.io/2017/05/10/SciPy%E7%94%9F%E6%80%81%E7%B3%BB%E7%BB%9F%E5%88%9D%E6%8E%A2/</guid>
        
        <category>SciPy</category>
        
        <category>Anaconda</category>
        
        <category>NumPy</category>
        
        <category>Matplotlib</category>
        
        <category>IPython</category>
        
        <category>Sympy</category>
        
        <category>pandas</category>
        
        <category>Tensorflow</category>
        
        <category>Theano</category>
        
        
        <category>python</category>
        
        <category>SciPy</category>
        
      </item>
    
      <item>
        <title>Jvm内存模型</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#section&quot; id=&quot;markdown-toc-section&quot;&gt;1.程序计数器&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#jvm&quot; id=&quot;markdown-toc-jvm&quot;&gt;2.JVM栈&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-1&quot; id=&quot;markdown-toc-section-1&quot;&gt;3.本地方法栈&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#java&quot; id=&quot;markdown-toc-java&quot;&gt;4.Java堆&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-2&quot; id=&quot;markdown-toc-section-2&quot;&gt;5.方法区&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#section-3&quot; id=&quot;markdown-toc-section-3&quot;&gt;5.1.运行时常量池&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Java开发人员无需过多考虑因指针引起的如内存泄露和溢出问题，也不用为每个new出来的对象使用delete等方法来释放内存。JVM已经为开发人员处理好了这一切，但是由于各种原因，Java程序也会出现内存溢出等问题，如果不了解JVM的内存模型以及相关的管理策略，那么整个排查过程将会变得十分艰难。
&lt;img src=&quot;http://7xriy2.com1.z0.glb.clouddn.com/JVM%20mem%20model.png&quot; alt=&quot;JVM mem model&quot; title=&quot;JVM mem model&quot; /&gt;&lt;/p&gt;

&lt;p&gt;JVM的运行时内存共有5块区域，其中有3个是线程间隔离的，有2个是线程间共享的。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;1.程序计数器&lt;/h2&gt;
&lt;p&gt;它是线程间隔离的。字节码的行号指示器，用来标记当前线程所执行的字节码的行号。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Q1. 为什么每个线程都需要一个独立的计数器呢？
因为JVM的多线程是轮询在CPU上执行的，任何一个时间点，一个处理器上最多只有一条指定在执行。为保证线程切换后，能恢复从正确的执行位置执行指令，所以给每个线程都独立的使用一块空间作为程序计数器，使得多线程之间计数器互不影响。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;jvm&quot;&gt;2.JVM栈&lt;/h2&gt;

&lt;p&gt;它是线程间隔离的，也就是常说到的“栈内存”。每个方法执行的时候都会创建一个栈桢，用来存放局部变量表用来存放该方法内使用到的局部变量表、操作数栈、动态链接、方法出口灯信息。一个方法从调用到执行完成的过程也就对应着一个栈桢在JVM栈中入栈到出栈的过程。
局部变量表中存放了编译器可确定的各种基本数据类型（例如：boolean、byte、char、short等等），以及对象的引用。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;3.本地方法栈&lt;/h2&gt;

&lt;p&gt;它是线程间隔离的，和“JVM栈”的区别是：“JVM栈”是执行Java方法时所使用到的内存；“本地方法栈”是JVM执行Native方法时所使用到的内存存。
这一块内存在JVM规范中没有强制指定，所以不同的虚拟机实现它的方法可能不一样。Sum HotSpot虚拟机是把“JVM栈”和“本地方法栈”合二为一的。&lt;/p&gt;

&lt;h2 id=&quot;java&quot;&gt;4.Java堆&lt;/h2&gt;
&lt;p&gt;它是线程间共享的，存放JVM对象实例，也是GC发生的主要区域，所以也被称为GC堆。
关于GC算法垃圾回收器，后边会介绍。&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;5.方法区&lt;/h2&gt;
&lt;p&gt;它是线程间共享的，存放已被JVM加载的类信息、常量、静态变量、即时编译器编译后的代码等。&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;5.1.运行时常量池&lt;/h3&gt;
&lt;p&gt;它是方法区的一部分，存放编译器生成的各种常量值。&lt;/p&gt;
</description>
        <pubDate>Wed, 05 Apr 2017 00:00:00 +0800</pubDate>
        <link>http://leocook.github.io/2017/04/05/JVM%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/</link>
        <guid isPermaLink="true">http://leocook.github.io/2017/04/05/JVM%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/</guid>
        
        <category>jvm</category>
        
        
        <category>java</category>
        
      </item>
    
      <item>
        <title>2016书单</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#section&quot; id=&quot;markdown-toc-section&quot;&gt;1.《西游记》&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#spark&quot; id=&quot;markdown-toc-spark&quot;&gt;2.《Spark最佳实践》&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#spark-1&quot; id=&quot;markdown-toc-spark-1&quot;&gt;3.《Spark快速大数据分析》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;2016年看的书主要还是以技术类的比价多，意料之外的是看完了《西游记》。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;1.《西游记》&lt;/h2&gt;

&lt;p&gt;和86版的电视剧差别挺大，在北京时，主要是坐地铁的时候看完的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://7xriy2.com1.z0.glb.clouddn.com/xiyouji.png&quot; alt=&quot;西游记&quot; title=&quot;西游记&quot; /&gt;&lt;/p&gt;

&lt;p&gt;图书地址：https://www.amazon.cn/dp/B00C4PGGUW&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;spark&quot;&gt;2.《Spark最佳实践》&lt;/h2&gt;

&lt;p&gt;同类目书籍中，比较偏向实战，推荐。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img3.doubanio.com/lpic/s28707922.jpg&quot; alt=&quot;Spark最佳实践&quot; title=&quot;Spark最佳实践&quot; /&gt;&lt;/p&gt;

&lt;p&gt;图书地址：https://item.jd.com/11923673.html&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;spark-1&quot;&gt;3.《Spark快速大数据分析》&lt;/h2&gt;

&lt;p&gt;spark入门级别的书，写得比较细致，也可以作为手册查询，内容基本上都是官网翻译过来的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.doubanio.com/lpic/s28300707.jpg&quot; alt=&quot;Spark快速大数据分析&quot; title=&quot;Spark快速大数据分析&quot; /&gt;&lt;/p&gt;

&lt;p&gt;图书地址：https://item.jd.com/11782888.html&lt;/p&gt;

</description>
        <pubDate>Fri, 30 Dec 2016 00:00:00 +0800</pubDate>
        <link>http://leocook.github.io/2016/12/30/2016%E4%B9%A6%E5%8D%95/</link>
        <guid isPermaLink="true">http://leocook.github.io/2016/12/30/2016%E4%B9%A6%E5%8D%95/</guid>
        
        <category>书单</category>
        
        
        <category>书单</category>
        
      </item>
    
      <item>
        <title>Spark内存管理</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#reserved-memory&quot; id=&quot;markdown-toc-reserved-memory&quot;&gt;1.Reserved Memory&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#user-memory&quot; id=&quot;markdown-toc-user-memory&quot;&gt;2.User Memory&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#spark-memory&quot; id=&quot;markdown-toc-spark-memory&quot;&gt;3.Spark Memory&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#storage-memory&quot; id=&quot;markdown-toc-storage-memory&quot;&gt;3.1.Storage Memory&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#execution-memory&quot; id=&quot;markdown-toc-execution-memory&quot;&gt;3.2.Execution Memory&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#storage-memoryexecution-memory&quot; id=&quot;markdown-toc-storage-memoryexecution-memory&quot;&gt;3.3.Storage Memory和Execution Memory共享规则&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Spark的最大卖点就是内存迭代运算，相对于传统MapReduce的磁盘迭代运算，spark的迭代运算要快得多。作为内存迭代运算的spark，掌握它的内存管理是很有必要的。&lt;/p&gt;

&lt;p&gt;Spark的内存可以大体上分为三大块：Reserved Memory（预留内存）、User Memory（用户内存），以及Spark Memory（Spark内存）。Spark Memory又包含Storage Memory和Execution Memory这两大块，1.6版本之前他们是不能共享的，从1.6版本(如下图)开始它们就可以共享了。&lt;strong&gt;而本文介绍的就是1.6版本开始之后内存管理机制。&lt;/strong&gt;
&lt;img src=&quot;http://7xriy2.com1.z0.glb.clouddn.com/spark%20m.png&quot; alt=&quot;spark mem&quot; title=&quot;spark mem&quot; /&gt;&lt;/p&gt;

&lt;p&gt;本文在描述spark各个部分内存的时候，大概从三个方面介绍：概念描述、该内存参数怎么配置，内存不够的时候会发生什么情况。&lt;/p&gt;

&lt;h2 id=&quot;reserved-memory&quot;&gt;1.Reserved Memory&lt;/h2&gt;

&lt;p&gt;系统预留内存，用于存储Spark内部对象。它的大小是300MB，不能通过参数修改，如果真的需要修改，需要重新编译（spark.testing.reservedMemory参数可以使用，但是不推荐在线上环境中使用）。&lt;/p&gt;

&lt;p&gt;当executor分配的内存小于1.5*Reserved Memory的时候，将会报“please use larger heap size”错误。&lt;/p&gt;

&lt;h2 id=&quot;user-memory&quot;&gt;2.User Memory&lt;/h2&gt;

&lt;p&gt;用户内存，用于存储RDD转换操作所需要的数据，例如RDD依赖等信息。
这个内存大小为(“Java Heap” – “Reserved Memory”) * (1.0 – spark.memory.fraction)，默认是(“Java Heap” – 300MB) * 0.25。如果用户使用的内存大于这个值，将会导致OOM。&lt;/p&gt;

&lt;h2 id=&quot;spark-memory&quot;&gt;3.Spark Memory&lt;/h2&gt;

&lt;p&gt;这部分内存是归Spark自身管理的，大小为(“Java Heap” – “Reserved Memory”) * spark.memory.fraction，默认为(“Java Heap” – 300MB) * 0.75。Spark Memory又被分为Storage Memory和Execution Memory，下面详细说明。&lt;/p&gt;

&lt;h3 id=&quot;storage-memory&quot;&gt;3.1.Storage Memory&lt;/h3&gt;

&lt;p&gt;用来存储spark的cache数据，例如RDD的缓存、unroll数据。当缓存数据的持久化level达到一定的时候，spark将会把它存到磁盘中，例如广播变量的数据持久化级别都是“MEMORY_AND_DISK”，所以所有的广播变量数据大小达到一定量的时候，都会存到磁盘中的。默认大小是Spark Memory的0.5，可用过参数spark.memory.storageFraction来配置（spark.memory.storageFraction=0.5）。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Unroll Memory&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;“Unroll Memory”是”Storage Memory”的一部分，在Spark中数据可以以序列化和反序列化的形式存储，序列化后的数据是无法直接被访问的，只有反序列化后才能被使用，反序列化过程中用到的RAM就是Unroll Memory。Spark中的大部分数据都是以序列化的形式传输的。&lt;/p&gt;

&lt;h3 id=&quot;execution-memory&quot;&gt;3.2.Execution Memory&lt;/h3&gt;

&lt;p&gt;用于存储spark的buffer部分，例如task运行过程中产生的一些对象，shuffle过程中map的输出，在内存不够的时候，支持写到磁盘上。Spark Memory中能被应用使用的内存中，除了Storage Memory剩余内存都是Execution Memory的了。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Shuffle Memory&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;shuffle阶段使用的内存，主要是使用在sort上。如果这一块没有足够的内存来用作shuffle，将会内存溢出失败。
当然，在内存不足的时候，也可以使用spark的外部排序（spark.shuffle.spill=true），但是性能将会有些折扣。&lt;/p&gt;

&lt;h3 id=&quot;storage-memoryexecution-memory&quot;&gt;3.3.Storage Memory和Execution Memory共享规则&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;一方空闲，一方内存不足的时候，内存不足的一方可以借用另一方的内存。&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Storage Memory占用了Execution Memory的内存，当Execution Memory内存不够用时&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;强制释放Storage Memory中属于Execution Memory的那部分内存，释放后的内存被Execution Memory使用。Storage Memory丢失的数据在下次使用的时候会被重新计算。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Execution Memory占用了Storage Memory的内存，当Storage Memory内存不够用时&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;不强制释放Execution Memory中属于Storage Memory的那部分内存，Storage Memory会一直等待，直到Execution Memory主动释放属于Storage Memory的那部分内存。因为强制释放Execution Memory会导致任务失败。&lt;/p&gt;

&lt;p&gt;（PS：感觉Execution Memory在欺负Storage Memory，有木有~~~）&lt;/p&gt;

</description>
        <pubDate>Thu, 13 Oct 2016 00:00:00 +0800</pubDate>
        <link>http://leocook.github.io/2016/10/13/spark%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</link>
        <guid isPermaLink="true">http://leocook.github.io/2016/10/13/spark%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</guid>
        
        <category>spark</category>
        
        
        <category>spark</category>
        
      </item>
    
      <item>
        <title>Spark streaming最佳实践 概述</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#section&quot; id=&quot;markdown-toc-section&quot;&gt;1.内存溢出&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-1&quot; id=&quot;markdown-toc-section-1&quot;&gt;2.外部系统连接数过多&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-2&quot; id=&quot;markdown-toc-section-2&quot;&gt;3.资源分配的浪费&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Spark streaming是基于Spark core的，天然的具备易扩展、高吞吐量，以及自动容错等特性。支持的主流数据源有Kafka、Flume、HDFS、Twitter、TCP socket等等，Spark的数据输出在spark streaming中都支持，对于有spark基础的开发人员来说，开发spark streaming应用成本将会少很多。本文是一篇概述型的文章，相关详细的配置会在后边逐渐补上。&lt;/p&gt;

&lt;p&gt;Spark streaming在企业实战中经常回到这么几类问题：内存溢出、外部系统连接数过多、分配的资源超过了程序所需要的资源，造成资源浪费。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;1.内存溢出&lt;/h2&gt;

&lt;p&gt;Spark内存大概分为了两类：Execution Memory和Storage Memory，前者主要用来做buffer的，例如joins、shuffle、sort等等；后者主要用来做cache，例如RDD的数据存储、广播变量、task结果数据等等。从1.6版本之前这两部分内存是不能共享的，从1.6开始之后这两部分内存就可以共享了。&lt;/p&gt;

&lt;p&gt;我遇到的内存溢出问题大概有三类，通常是单个分区处理的数据量过多：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;a).数据倾斜引；&lt;/li&gt;
  &lt;li&gt;b).数据未倾斜，分区数过少；&lt;/li&gt;
  &lt;li&gt;c).某个分区中产生了一个较大的内存集合，例如大的List、Set，或者Map。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这类问题在spark core中也是经常会出现的，关于数据倾斜的问题以后会详细讲解。入手一个新的业务时，应该对该业务的数据量有个大概的预估，这样给这个应用分配多少节点，每个节点会处理多大的数据量，这样就能很好的预估出每个节点分配多少资源比较合理了。&lt;/p&gt;

&lt;p&gt;为了避免内存溢出，可以从下面几个方向来做：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;a).避免数据倾斜；&lt;/li&gt;
  &lt;li&gt;b).评估每个分区的数据量，给每个分区分配合理的资源；&lt;/li&gt;
  &lt;li&gt;c).控制好List、Set等集合的大小；&lt;/li&gt;
  &lt;li&gt;d).控制Spark streaming读取源数据的最大速度（spark.streaming.kafka.maxRatePerPartition），实时数据流量有高峰和低谷，不同时间处理的数据量是不一样的，为防止数据高峰的时候内存溢出，这里有必要做配置；&lt;/li&gt;
  &lt;li&gt;e).配置Spark streaming可动态控制读取数据源的速度（spark.streaming.backpressure.enabled）。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-1&quot;&gt;2.外部系统连接数过多&lt;/h2&gt;

&lt;p&gt;在使用spark streaming解决问题的时候，经常会对外部数据源进行读写操作，切记每次读写完成之后需要关闭网络连接。在我们以往的编程经验中，这些思维都是一直持有的。 &lt;br /&gt;
在往hbase写入数据的时候，如果你使用了RDD.saveAsHadoopDataset方法，就需要注意了，org.apache.hadoop.hbase.mapred.TableOutputFormat类存在bug：不能释放zookeeper连接，导致在往hbase写数据的时候，zookeeper的连接数不停得增长。&lt;/p&gt;

&lt;p&gt;推荐使用下面这种写法：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
import org.apache.hadoop.mapreduce.Job
import org.apache.hadoop.hbase.mapreduce.TableOutputFormat

val conf = HBaseConfiguration.create()
conf.set(&quot;hbase.zookeeper.quorum&quot;, zk_hosts)
conf.set(&quot;hbase.zookeeper.property.clientPort&quot;, zk_port)

conf.set(TableOutputFormat.OUTPUT_TABLE, &quot;TABLE_NAME&quot;)
val job = Job.getInstance(conf)
job.setOutputFormatClass(classOf[TableOutputFormat[String]])

formatedLines.map{
  case (a,b, c) =&amp;gt; {
    val row = Bytes.toBytes(a)

    val put = new Put(row)
    put.setDurability(Durability.SKIP_WAL)

    put.addColumn(Bytes.toBytes(&quot;cf&quot;), Bytes.toBytes(&quot;node&quot;), Bytes.toBytes(b))
    put.addColumn(Bytes.toBytes(&quot;cf&quot;), Bytes.toBytes(&quot;topic&quot;), Bytes.toBytes(c))

    (new ImmutableBytesWritable(row), put)
  }
}.saveAsNewAPIHadoopDataset(job.getConfiguration)

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;section-2&quot;&gt;3.资源分配的浪费&lt;/h2&gt;

&lt;p&gt;如果实时数据在每天的某个时间点有着平时的几倍的数据量，如果给该作业分配过多的资源，那么在绝大多数，这些资源都是闲置浪费的。这里可以启用动态资源分配。&lt;/p&gt;

&lt;p&gt;关于配置介绍可以查看官方文档：http://spark.apache.org/docs/latest/job-scheduling.html#dynamic-resource-allocation&lt;/p&gt;

&lt;p&gt;如果启用该配置，需要做如下配置：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;1.在spark应用中配置spark.dynamicAllocation.enabled=true &lt;br /&gt;
2.每个节点启动外部shuffle服务，并在spark应用中配置spark.shuffle.service.enabled=true&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;关于外部shuffle服务，在standalone、Mesos，yarn中的配置是不一样的。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;standalone&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;启动worker的时候指定spark.shuffle.service.enabled=true&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Mesos&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在所有节点上配置spark.shuffle.service.enabled=true，然后执行$SPARK_HOME/sbin/start-mesos-shuffle-service.sh&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;yarn&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;a.添加yarn的配置文件，重新编译spark。如果使用官方编译好的安装包，可以忽略这一步。
b.找到spark-&lt;version&gt;-yarn-shuffle.jar。如果自己编译spark的话，在目录$SPARK_HOME/common/network-yarn/target/scala-&lt;version&gt;下；如果是使用官方编译好的spark，在lib目录下寻找。
c.添加到spark-&lt;version&gt;-yarn-shuffle.jar到yarn所有NodeManager的classpath下。
d.配置所有NodeManager的yarn-site.xml文件如下：&lt;/version&gt;&lt;/version&gt;&lt;/version&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;yarn.nodemanager.aux-services&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;spark_shuffle&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;yarn.nodemanager.aux-services.spark_shuffle.class&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;org.apache.spark.network.yarn.YarnShuffleService&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;e.重启所有的NodeManager&lt;/p&gt;

&lt;p&gt;spark on yarn配置了外部shuffle之后，&lt;code&gt;--num-executors&lt;/code&gt;配置将不再生效。&lt;/p&gt;

</description>
        <pubDate>Wed, 12 Oct 2016 00:00:00 +0800</pubDate>
        <link>http://leocook.github.io/2016/10/12/spark-streaming%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5-%E6%A6%82%E8%BF%B0/</link>
        <guid isPermaLink="true">http://leocook.github.io/2016/10/12/spark-streaming%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5-%E6%A6%82%E8%BF%B0/</guid>
        
        <category>spark</category>
        
        
        <category>spark</category>
        
      </item>
    
      <item>
        <title>Lua_on_nginx</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#section&quot; id=&quot;markdown-toc-section&quot;&gt;1.系统环境&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#lua&quot; id=&quot;markdown-toc-lua&quot;&gt;2.Lua的运行时环境配置&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#lua-1&quot; id=&quot;markdown-toc-lua-1&quot;&gt;2.1.下载Lua的运行环境&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-1&quot; id=&quot;markdown-toc-section-1&quot;&gt;2.2.编译安装&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#nginxlua&quot; id=&quot;markdown-toc-nginxlua&quot;&gt;3.下载Nginx的lua模块&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#nginx&quot; id=&quot;markdown-toc-nginx&quot;&gt;4.Nginx配置&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#nginx-1&quot; id=&quot;markdown-toc-nginx-1&quot;&gt;4.1.下载nginx&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-2&quot; id=&quot;markdown-toc-section-2&quot;&gt;4.2.编译安装&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-3&quot; id=&quot;markdown-toc-section-3&quot;&gt;4.3.配置&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#nginx-2&quot; id=&quot;markdown-toc-nginx-2&quot;&gt;4.4.启动nginx&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-4&quot; id=&quot;markdown-toc-section-4&quot;&gt;4.5.验证&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#faq&quot; id=&quot;markdown-toc-faq&quot;&gt;5.FAQ&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#pcre3&quot; id=&quot;markdown-toc-pcre3&quot;&gt;5.1.缺少pcre3&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#libssl&quot; id=&quot;markdown-toc-libssl&quot;&gt;5.2.缺少libssl&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Nginx的高并发是它的一大显著优势，Lua则是一门较为轻便的脚本语言。把他们组合在一起，则极大的增强了Nginx的能力（灵活性，扩展性）。
Nginx-Lua模块是由淘宝开发的第三方模块，使用它可以把Lua内嵌到Nginx中。&lt;/p&gt;

&lt;p&gt;nginx  地址：http://www.nginx.org&lt;/p&gt;

&lt;p&gt;luajit 地址：http://luajit.org/download.html&lt;/p&gt;

&lt;p&gt;HttpLuaModule 地址：http://wiki.nginx.org/HttpLuaModule&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;1.系统环境&lt;/h2&gt;

&lt;p&gt;必须的编译环境，需要提前准备好。我这里的环境是ubuntu14.04，用的apt source是官方的源，使用163 source的时候有问题。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;apt-get install make
apt-get install gcc
apt-get install libpcre3 libpcre3-dev
apt-get install libssl-dev
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;lua&quot;&gt;2.Lua的运行时环境配置&lt;/h2&gt;

&lt;h3 id=&quot;lua-1&quot;&gt;2.1.下载Lua的运行环境&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd /opt/

wget http://luajit.org/download/LuaJIT-2.0.4.tar.gz

tar zxvf LuaJIT-2.0.4.tar.gz
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-1&quot;&gt;2.2.编译安装&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd /opt/LuaJIT-2.0.4
make
make install
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;nginxlua&quot;&gt;3.下载Nginx的lua模块&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd /opt/

wget https://github.com/openresty/lua-nginx-module/archive/v0.10.5.tar.gz

tar zxvf v0.10.5.tar.gz
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;nginx&quot;&gt;4.Nginx配置&lt;/h2&gt;

&lt;h3 id=&quot;nginx-1&quot;&gt;4.1.下载nginx&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd /opt/

wget http://nginx.org/download/nginx-1.10.1.tar.gz

tar zxvf nginx-1.10.1.tar.gz
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-2&quot;&gt;4.2.编译安装&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 导入环境变
export LUAJIT_LIB=/usr/local/lib
export LUAJIT_INC=/usr/local/include/luajit-2.0

# 安装到/usr/local/nginx-1.10.1目录下
./configure --prefix=/usr/local/nginx-1.10.1 --add-module=../lua-nginx-module-0.10.5

make -j2
make install
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-3&quot;&gt;4.3.配置&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd /usr/local/nginx-1.10.1
vi conf/nginx.conf
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;然后在http -&amp;gt; server下加入配置：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;location /lua_test {
    default_type 'text/plain';
    content_by_lua 'ngx.say(&quot;hello, ttlsa lua&quot;)';
}

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这个配置后，访问http://[hostname]:[port]/lua_test，就能访问你所定义的代码块了。&lt;/p&gt;

&lt;p&gt;如果你还想修改nginx的http端口，修改一下&lt;strong&gt;http.server&lt;/strong&gt;中的&lt;strong&gt;listen&lt;/strong&gt;值，就可以了。&lt;/p&gt;

&lt;h3 id=&quot;nginx-2&quot;&gt;4.4.启动nginx&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/usr/local/nginx-1.10.1/sbin/nginx
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-4&quot;&gt;4.5.验证&lt;/h3&gt;

&lt;p&gt;查看端口的运行情况：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;root@ubuntu:~# netstat -anp|grep 4002
tcp        0      0 0.0.0.0:4002            0.0.0.0:*               LISTEN      1736/nginx
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;或者直接请求4002端口。（我这里使用的是4002端口，你可以根据需要，设置为你需要的。）&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-`&quot;&gt;root@ubuntu:/usr/local/nginx-1.10.1/sbin# curl http://192.168.1.160:4002/lua_test
hello, ttlsa lua
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;faq&quot;&gt;5.FAQ&lt;/h2&gt;

&lt;h3 id=&quot;pcre3&quot;&gt;5.1.缺少pcre3&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;错误log&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./configure: error: the HTTP rewrite module requires the PCRE library.
You can either disable the module by using --without-http_rewrite_module
option, or install the PCRE library into the system, or build the PCRE library
statically from the source with nginx by using --with-pcre=&amp;lt;path&amp;gt; option.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;解决办法&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;apt-get install libpcre3 libpcre3-dev
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;libssl&quot;&gt;5.2.缺少libssl&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;错误log&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./configure: error: the HTTP gzip module requires the zlib library.
You can either disable the module by using --without-http_gzip_module
option, or install the zlib library into the system, or build the zlib library
statically from the source with nginx by using --with-zlib=&amp;lt;path&amp;gt; option.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;解决办法&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;apt-get install libssl-dev
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;参考地址：
http://www.ttlsa.com/nginx/nginx-modules-ngx_lua/&lt;/p&gt;

</description>
        <pubDate>Tue, 26 Jul 2016 00:00:00 +0800</pubDate>
        <link>http://leocook.github.io/2016/07/26/Lua_on_Nginx/</link>
        <guid isPermaLink="true">http://leocook.github.io/2016/07/26/Lua_on_Nginx/</guid>
        
        <category>nginx</category>
        
        <category>lua</category>
        
        
        <category>nginx</category>
        
      </item>
    
      <item>
        <title>Install_hadoop_cluster_on_cm</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#cloudera-manager&quot; id=&quot;markdown-toc-cloudera-manager&quot;&gt;1.Cloudera Manager安装前准备&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#section&quot; id=&quot;markdown-toc-section&quot;&gt;1.1. 操作系统的优化&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-1&quot; id=&quot;markdown-toc-section-1&quot;&gt;1.2. 数据的存放&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#cloudera-manager-1&quot; id=&quot;markdown-toc-cloudera-manager-1&quot;&gt;2.开始安装Cloudera Manager&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#cm&quot; id=&quot;markdown-toc-cm&quot;&gt;2.1.下载CM&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-2&quot; id=&quot;markdown-toc-section-2&quot;&gt;2.2.配置私有软件仓库(如果不使用私有仓库，这里可以直接跳过)&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#section-3&quot; id=&quot;markdown-toc-section-3&quot;&gt;2.2.1.创建一个临时可以使用的远程仓库&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#cm-1&quot; id=&quot;markdown-toc-cm-1&quot;&gt;2.2.2.配置安装CM所需要的私有仓库&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#cm-2&quot; id=&quot;markdown-toc-cm-2&quot;&gt;2.2.3.配置使用CM安装节点时会用到的仓库&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#jdk&quot; id=&quot;markdown-toc-jdk&quot;&gt;2.2.4.配置节点的JDK&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#cm-3&quot; id=&quot;markdown-toc-cm-3&quot;&gt;2.3.开始安装CM&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#cm-4&quot; id=&quot;markdown-toc-cm-4&quot;&gt;2.4.使用CM安装集群&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-4&quot; id=&quot;markdown-toc-section-4&quot;&gt;3.注意事项&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#host&quot; id=&quot;markdown-toc-host&quot;&gt;3.1.主机的Host配置不能出差错&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#cm-agent&quot; id=&quot;markdown-toc-cm-agent&quot;&gt;3.2.cm-agent安装失败重试时&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-5&quot; id=&quot;markdown-toc-section-5&quot;&gt;4.会用到的一些地址总结&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#mysql&quot; id=&quot;markdown-toc-mysql&quot;&gt;4.1.Mysql的相关配置&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-6&quot; id=&quot;markdown-toc-section-6&quot;&gt;4.2.创建本地仓库&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#parcel&quot; id=&quot;markdown-toc-parcel&quot;&gt;4.3.parcel的下载地址&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#cm-5&quot; id=&quot;markdown-toc-cm-5&quot;&gt;4.4.cm的下载地址&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-7&quot; id=&quot;markdown-toc-section-7&quot;&gt;5.附件&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对于Hadoop这个复杂的大系统，我们期望能有一个平台，可以对Hadoop的每一个部件都能够进行安装部署，以及细颗粒度的监控。Apache发行版的Hadoop可以使用Ambari；Cloudera公司的CDH版本Hadoop则可以使用Cloudera Manager（后面简称为CM）来统一管理和部署。咱们这里的操作系统使用的是ubuntu14.04.&lt;/p&gt;

&lt;h2 id=&quot;cloudera-manager&quot;&gt;1.Cloudera Manager安装前准备&lt;/h2&gt;

&lt;h3 id=&quot;section&quot;&gt;1.1. 操作系统的优化&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;打开的最大文件数
修改当前的session配置(临时)：&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ulimit -SHn 65535
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;永久修改（需要重启服务器）：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo echo &quot;ulimit -SHn 65535&quot; &amp;gt;&amp;gt; /etc/rc.local
sudo chmod +x /etc/rc.local
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;打开的组大文件句柄数
临时配置&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 一般可不做修改，这是临时配置
sudo echo 2000000 &amp;gt; /proc/sys/fs/file-max
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;永久配置&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;echo &quot;echo 2000000 &amp;gt; /proc/sys/fs/file-max&quot; &amp;gt;&amp;gt; /etc/rc.local
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;或者&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo echo &quot;fs.file-max = 2000000&quot; &amp;gt;&amp;gt;/etc/sysctl.conf #推荐
#使文件生效sudo /sbin/sysctl -p
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;打开的最大网络连接数&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo echo &quot;net.core.somaxconn = 2048&quot; &amp;gt;&amp;gt;/etc/sysctl.conf
sudo /sbin/sysctl -p
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;关闭selinux&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ubuntu默认是不安装的selinux的，所以这里可以直接忽略。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;配置ntp&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;安装&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;apt-get install ntp
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;如果只需要保证集群内部的各个server之间时间保持同步，只需要在需要同步的机器上配置：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;0 */12 * * * ntpdate dt-vt-154
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;如果需要时间和互联网的时间保持一致，那么就需要在提供ntp server的机器上配置上层ntpserver:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;server [ntpserver_01]
server [ntpserver_02]
server [ntpserver_03]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;关闭防火墙&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo ufw disable #关闭防火墙
apt-get remove iptables #卸载防火墙
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;配置好hosts映射文件&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;vi /etc/hosts

192.168.1.151   dt-vt-151
192.168.1.152   dt-vt-152
192.168.1.153   dt-vt-153
192.168.1.154   dt-vt-154
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Java环境配置&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;安装&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mkdir /opt/java
cd /opt/java
#下载到安装文件到这个目录
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;环境配置&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;vi /etc/profile

export JAVA_HOME=/opt/java/jdk1.7.0_79
export CLASSPATH=.:$JAVA_HOME/lib
export PATH=$JAVA_HOME/bin:$PATH
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;执行下面命令，使当前的session生效：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;source /etc/profile
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-1&quot;&gt;1.2. 数据的存放&lt;/h3&gt;
&lt;p&gt;在使用CM来管理集群的时候，会涉及到大量的数据存储，例如Hadoop的主机列表信息，主机的配置信息，负载信息，各个模块的运行时状态等等。
咱们这里使用mysql来作为CM的数据存储，这里不仅是CM，Hadoop中的Hive等模块的元数据，都来使用mysql存储。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;安装mysql&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo apt-get install mysql-server
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;我这里安装完后是5.5.49.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;关闭mysql，备份配置文件&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/etc/init.d/mysql stop
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;把/var/lib/mysql/ib_logfile0和/var/lib/mysql/ib_logfile1拷贝至某个配置目录中，例如：/var/lib/mysql/bak&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;配置InnoDB引擎&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;务必使用InnoDB引擎引擎，若是使用MyISAM引擎CM将启动不了。在Mysql的命令行中运行下面的命令，来查看你的Mysql使用了哪个引擎。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mysql&amp;gt; show table status;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;配置mysql的innodb刷写模式&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;innodb_flush_method=O_DIRECT
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;即：配置Innodb的刷写模式为异步写模式。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;修改mysql的最大连接数&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;max_connections=1550
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;在这里，你应该会考虑配置该数值为多少比较合适。
当集群规模&lt;strong&gt;小于50台&lt;/strong&gt;的时候，假设该库中有N个数据库是用来服务于Hadoop的，那么max_connections可以设置为100*N+50。例如：Cloudera Manager Server, Activity Monitor, Reports Manager, Cloudera Navigator, 和 Hive metastore都是使用mysql的，那么就配置max_connections为550.
当集群规模&lt;strong&gt;大于50台&lt;/strong&gt;的时候，建议每个数据库只存放在一台机器上。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;配置文件样例&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[mysqld]
transaction-isolation = READ-COMMITTED
# Disabling symbolic-links is recommended to prevent assorted security risks;
# to do so, uncomment this line:
# symbolic-links = 0

key_buffer = 16M
key_buffer_size = 32M
max_allowed_packet = 32M
thread_stack = 256K
thread_cache_size = 64
query_cache_limit = 8M
query_cache_size = 64M
query_cache_type = 1

max_connections = 1550
#expire_logs_days = 10
#max_binlog_size = 100M


# InnoDB settings
innodb_file_per_table = 1
innodb_flush_log_at_trx_commit  = 2
innodb_log_buffer_size = 64M
innodb_buffer_pool_size = 4G
innodb_thread_concurrency = 8
innodb_flush_method = O_DIRECT
innodb_log_file_size = 512M

[mysqld_safe]
log-error=/var/log/mysqld.log
pid-file=/var/run/mysqld/mysqld.pid

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;启动mysql&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/etc/init.d/mysql start
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;打开开机自启&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;apt-get install sysv-rc-conf
sysv-rc-conf mysql on
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;安装mysql-jdbc驱动&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;apt-get install libmysql-java
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;mysql远程连接&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;vi /etc/mysql/my.cnf

bind-address = 0.0.0.0
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;給相关服务创建mysql的数据库&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;相关列表如下：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Role&lt;/th&gt;
      &lt;th&gt;Database&lt;/th&gt;
      &lt;th&gt;User&lt;/th&gt;
      &lt;th&gt;Password&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Activity Monitor&lt;/td&gt;
      &lt;td&gt;amon&lt;/td&gt;
      &lt;td&gt;amon&lt;/td&gt;
      &lt;td&gt;amon_password&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Reports Manager&lt;/td&gt;
      &lt;td&gt;rman&lt;/td&gt;
      &lt;td&gt;rman&lt;/td&gt;
      &lt;td&gt;rman_password&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Hive Metastore Server&lt;/td&gt;
      &lt;td&gt;hive_metastore&lt;/td&gt;
      &lt;td&gt;hive&lt;/td&gt;
      &lt;td&gt;hive_password&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Sentry Server&lt;/td&gt;
      &lt;td&gt;sentry&lt;/td&gt;
      &lt;td&gt;sentry&lt;/td&gt;
      &lt;td&gt;sentry_password&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Cloudera Navigator Audit Server&lt;/td&gt;
      &lt;td&gt;nav&lt;/td&gt;
      &lt;td&gt;nav&lt;/td&gt;
      &lt;td&gt;nav_password&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Cloudera Navigator Metadata Server&lt;/td&gt;
      &lt;td&gt;navms&lt;/td&gt;
      &lt;td&gt;navms&lt;/td&gt;
      &lt;td&gt;navms_password&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;OOZIE&lt;/td&gt;
      &lt;td&gt;oozie&lt;/td&gt;
      &lt;td&gt;oozie&lt;/td&gt;
      &lt;td&gt;oozie&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;建表语句格式如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;create database database DEFAULT CHARACTER SET utf8;
grant all on database.* TO 'user'@'%' IDENTIFIED BY 'password';
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;建表语句如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;create database amon DEFAULT CHARACTER SET utf8;
grant all on amon.* TO 'amon'@'%' IDENTIFIED BY 'amon';

create database rmon DEFAULT CHARACTER SET utf8;
grant all on rmon.* TO 'rmon'@'%' IDENTIFIED BY 'rmon';

create database hive_metastore DEFAULT CHARACTER SET utf8;
grant all on hive_metastore.* TO 'hive'@'%' IDENTIFIED BY 'hive';

create database sentry DEFAULT CHARACTER SET utf8;
grant all on sentry.* TO 'sentry'@'%' IDENTIFIED BY 'sentry';

create database nav DEFAULT CHARACTER SET utf8;
grant all on nav.* TO 'nav'@'%' IDENTIFIED BY 'nav';

create database navms DEFAULT CHARACTER SET utf8;
grant all on navms.* TO 'navms'@'%' IDENTIFIED BY 'navms';

create database oozie DEFAULT CHARACTER SET utf8;
grant all on oozie.* TO 'oozie'@'%' IDENTIFIED BY 'oozie';
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;cloudera-manager-1&quot;&gt;2.开始安装Cloudera Manager&lt;/h2&gt;

&lt;h3 id=&quot;cm&quot;&gt;2.1.下载CM&lt;/h3&gt;

&lt;p&gt;可以下载安装最新版本的CM：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;wget http://archive.cloudera.com/cm5/installer/latest/cloudera-manager-installer.bin
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;当然，如果你想选择安装其它版本，可以访问下面的地址，并选择下载你所需要的版本(cm5+)：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;http://archive.cloudera.com/cm5/installer/
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;我这里使用的是版本是5.4.10，从release note上看，目前cdh5.4.10是最稳当的版本。我下载到了本地路径如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/opt/cm/cloudera-manager-installer.bin
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;修改权限，使其可以被执行：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;chmod u+x cloudera-manager-installer.bin
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-2&quot;&gt;2.2.配置私有软件仓库(如果不使用私有仓库，这里可以直接跳过)&lt;/h3&gt;

&lt;h4 id=&quot;section-3&quot;&gt;2.2.1.创建一个临时可以使用的远程仓库&lt;/h4&gt;
&lt;p&gt;这个配置是在安装cloudera-manager-server的时候才会用的。这里的仓库是使用传统的http协议，通过网络传输数据的。可以去http://archive.cloudera.com/cm5/repo-as-tarball/下载你所需要的cdh包。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;解压安装包&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下载完安装包后，解压到某个目录下，我这里下载的是cm5.4.10-ubuntu14-04.tar.gz这个版本。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tar -zxvf cm5.4.10-ubuntu14-04.tar.gz
chmod -R ugo+rX /opt/cm/local_resp/cm
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;解压后的目录是/opt/cm/local_resp/cm&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;启动Http server&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;启动一个Http服务，使可以通过网络来访问仓库中的数据。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd /opt/cm/
python -m SimpleHTTPServer 8900
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;我这里使用的是8900，你可以根据需要，使用指定的端口。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;验证&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;可在浏览器中访问地址http://server:8900/cm，如果可以正常访问，并且能看到相对应的文件列表，则表示正常启动。&lt;/p&gt;

&lt;h4 id=&quot;cm-1&quot;&gt;2.2.2.配置安装CM所需要的私有仓库&lt;/h4&gt;

&lt;p&gt;在目录&lt;strong&gt;/etc/apt/sources.list.d/&lt;/strong&gt;下创建文件&lt;strong&gt;my-private-cloudera-repo.list&lt;/strong&gt;，并写入配置把这个文件和上面新建的仓库关联到一起：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;vi /etc/apt/sources.list.d/my-private-cloudera-repo.list

deb [arch=amd64] http://192.168.1.154:8900/cm/ trusty-cm5.4.10 contrib
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;执行下面的命令，使得上面的配置生效：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo apt-get update
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;cm-2&quot;&gt;2.2.3.配置使用CM安装节点时会用到的仓库&lt;/h3&gt;
&lt;p&gt;可以下载地址：http://archive.cloudera.com/cm5/ubuntu/trusty/amd64/cm/ 里的所有内容到本地，然后使用&lt;strong&gt;2.2.1&lt;/strong&gt;中的方式来启动一个Http server。&lt;/p&gt;

&lt;h3 id=&quot;jdk&quot;&gt;2.2.4.配置节点的JDK&lt;/h3&gt;
&lt;p&gt;这一步是可选的，如果你不想每台机器都去手动安装，也可以在后边使用CM来批量安装。&lt;/p&gt;

&lt;h3 id=&quot;cm-3&quot;&gt;2.3.开始安装CM&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;连接互联网安装&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo ./cloudera-manager-installer.bin
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;或者&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;使用本地仓库安装&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo ./cloudera-manager-installer.bin --skip_repo_package=1
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;然后就是一路的YES &amp;amp; NEXT，最后安装完成，CM默认的端口是7180，账户名和密码都是7180.&lt;/p&gt;

&lt;h3 id=&quot;cm-4&quot;&gt;2.4.使用CM安装集群&lt;/h3&gt;

&lt;p&gt;首次登陆CM管理界面的时候，会出现一个集群安装向导。我这里选择的是免费版本。然后大概有如下几步：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;使用ip或者hostname来搜索主机，搜索到之后，go to next step.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;看到如下图片的时候，如果你已经在前面的主机中安装好了JDK，那么这里可以不选，如果没有，则必须选择。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;http://7xriy2.com1.z0.glb.clouddn.com/cm-02.png&quot; alt=&quot;CM JDK&quot; title=&quot;cm jdk&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;选择是否使用单用户模式（Single User Mode）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;不使用该模式的话，HDFS服务会使用“hdfs”账户来启动，Hbase的Region Server会使用“hbase”账户来启动。使用了该模式之后，所有的服务都是使用同一个账户去启动的。
这里主要看集群的使用场景，如果其中涉及到不同的模块是由不同人员来运维管理的话，我建议还是不要使用单用户模式了。但如果集群是统一由一个人员来管理，那么选择使用单用户模式可能会方便很多。
我这里没有使用单用户模式。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;配置好SSH登录&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;http://7xriy2.com1.z0.glb.clouddn.com/cm-03.png&quot; alt=&quot;配置ssh登录信息&quot; title=&quot;输入密码&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;配置好SSH后开始连入主机，安装jdk和cm-agent
&lt;img src=&quot;http://7xriy2.com1.z0.glb.clouddn.com/cm-04.png&quot; alt=&quot;install cm agent&quot; title=&quot;install cm agent&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;安装完成，此时cm-agent就已经安装好了，随时都可以使用cm-server控制安装Hadoop的相关组件,完成后先不要点击进入下一步，继续看下面。
&lt;img src=&quot;http://7xriy2.com1.z0.glb.clouddn.com/cm-05.png&quot; alt=&quot;cm agent ok&quot; title=&quot;cm agent ok&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;分发Hadoop的安装包&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;去地址：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;http://archive.cloudera.com/cdh5/parcels/5.4.10/
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;下载：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;CDH-5.4.10-1.cdh5.4.10.p0.16-trusty.parcel
CDH-5.4.10-1.cdh5.4.10.p0.16-trusty.parcel.sha1
manifest.json
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;下载完成后：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;把&quot;CDH-5.4.10-1.cdh5.4.10.p0.16-trusty.parcel.sha1&quot;重命名为&quot;CDH-5.4.10-1.cdh5.4.10.p0.16-trusty.parcel.sha&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;并移到目录：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/opt/cloudera/parcel-repo
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;然后在cm-serve点击进入下一页，将会看到如下图：
&lt;img src=&quot;http://7xriy2.com1.z0.glb.clouddn.com/cm-06.png&quot; alt=&quot;cm parcel distributed&quot; title=&quot;cm parcel distributed&quot; /&gt;
因为你已经把安装包下载好，并且放入到/opt/cloudera/parcel-repo（默认的目录）里面，所以这里的&lt;strong&gt;Download&lt;/strong&gt;自然就是100%，&lt;strong&gt;Distributed&lt;/strong&gt;是把安装包从cm-server往集群中各个节点分发的过程，&lt;strong&gt;Unpacked&lt;/strong&gt;是表示各个节点的上安装包的解压情况进度，前面都OK后，&lt;strong&gt;Activated&lt;/strong&gt;自然就可以了，表示安装包已经部署好了，可以随时进行安装。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;选择安装Hadoop的那些组件之后，会在这里显示各个组件部署的主机地址。
&lt;img src=&quot;http://7xriy2.com1.z0.glb.clouddn.com/cm-07.png&quot; alt=&quot;hosts choose&quot; title=&quot;hosts choose&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;这里配置的是一些组件使用的mysql信息：
&lt;img src=&quot;http://7xriy2.com1.z0.glb.clouddn.com/cm-08.png&quot; alt=&quot;hadoop mysql config&quot; title=&quot;hadoop mysql config&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;然后可以配置一些服务的的具体参数
&lt;img src=&quot;http://7xriy2.com1.z0.glb.clouddn.com/cm-09.png&quot; alt=&quot;hadoop config&quot; title=&quot;hadoop config&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;参数配置都没问题后，开始执行安装。
&lt;img src=&quot;http://7xriy2.com1.z0.glb.clouddn.com/cm-10.png&quot; alt=&quot;hadoop install&quot; title=&quot;hadoop install&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;安装完成后。
&lt;img src=&quot;http://7xriy2.com1.z0.glb.clouddn.com/cm-11.jpeg&quot; alt=&quot;install success&quot; title=&quot;install success&quot; /&gt;
PS：我这里的Kafka是后来安装上去的，默认Hadoop的parcel包是没有kafka的。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-4&quot;&gt;3.注意事项&lt;/h2&gt;

&lt;h3 id=&quot;host&quot;&gt;3.1.主机的Host配置不能出差错&lt;/h3&gt;
&lt;p&gt;我就配置错过host，期间走了一些弯路，主要表现在添加完主机之后，Hosts下的主机名都是localhost。&lt;/p&gt;

&lt;h3 id=&quot;cm-agent&quot;&gt;3.2.cm-agent安装失败重试时&lt;/h3&gt;
&lt;p&gt;如果在重试的过程中出现了一直等待，或者cm-agent端口被占用的情况，大概有下面的几种情况：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;锁文件没有删除&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo rm /tmp/.scm_prepare_node.lock
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;端口被占用 &lt;strong&gt;9000/9001&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这种情况是部分进程没有关闭成功，找到端口对应的进程号，然后然后使用&lt;strong&gt;kill -9停止进程&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;netstat -nap | grep 9000
netstat -nap | grep 9001
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;主要是&lt;strong&gt;supervisor&lt;/strong&gt;和&lt;strong&gt;cm-agent&lt;/strong&gt;进程&lt;/p&gt;

&lt;h2 id=&quot;section-5&quot;&gt;4.会用到的一些地址总结&lt;/h2&gt;

&lt;h3 id=&quot;mysql&quot;&gt;4.1.Mysql的相关配置&lt;/h3&gt;
&lt;p&gt;http://www.cloudera.com/documentation/enterprise/5-4-x/topics/cm_ig_mysql.html&lt;/p&gt;

&lt;h3 id=&quot;section-6&quot;&gt;4.2.创建本地仓库&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;For CM&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;http://www.cloudera.com/documentation/enterprise/5-4-x/topics/cm_ig_create_local_package_repo.html&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;For parcel&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;http://www.cloudera.com/documentation/enterprise/5-4-x/topics/cm_ig_create_local_parcel_repo.html&lt;/p&gt;

&lt;h3 id=&quot;parcel&quot;&gt;4.3.parcel的下载地址&lt;/h3&gt;

&lt;p&gt;http://archive.cloudera.com/cdh5/parcels/
http://archive.cloudera.com/kafka/parcels/&lt;/p&gt;

&lt;h3 id=&quot;cm-5&quot;&gt;4.4.cm的下载地址&lt;/h3&gt;

&lt;p&gt;加压后可以直接运行
http://archive.cloudera.com/cm5/cm/5/&lt;/p&gt;

&lt;h2 id=&quot;section-7&quot;&gt;5.附件&lt;/h2&gt;

&lt;p&gt;博文中的图片是压缩后的，清晰度比较低，原图可以访问下面的地址：&lt;/p&gt;

&lt;p&gt;链接: http://pan.baidu.com/s/1cmiBCE 密码: rnmw&lt;/p&gt;
</description>
        <pubDate>Sat, 23 Jul 2016 00:00:00 +0800</pubDate>
        <link>http://leocook.github.io/2016/07/23/Install_hadoop_cluster_on_CM/</link>
        <guid isPermaLink="true">http://leocook.github.io/2016/07/23/Install_hadoop_cluster_on_CM/</guid>
        
        <category>cm</category>
        
        <category>hadoop</category>
        
        
        <category>hadoop</category>
        
      </item>
    
      <item>
        <title>Elk安装配置介绍</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#section&quot; id=&quot;markdown-toc-section&quot;&gt;版本列表&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#logstash&quot; id=&quot;markdown-toc-logstash&quot;&gt;1.logstash配置&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#jdk&quot; id=&quot;markdown-toc-jdk&quot;&gt;1.1.Jdk安装&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#logstash-1&quot; id=&quot;markdown-toc-logstash-1&quot;&gt;1.2.下载logstash&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-1&quot; id=&quot;markdown-toc-section-1&quot;&gt;1.3.启动&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-2&quot; id=&quot;markdown-toc-section-2&quot;&gt;1.4.验证&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#es&quot; id=&quot;markdown-toc-es&quot;&gt;2.ES&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#section-3&quot; id=&quot;markdown-toc-section-3&quot;&gt;2.1.下载&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-4&quot; id=&quot;markdown-toc-section-4&quot;&gt;2.2.配置&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-5&quot; id=&quot;markdown-toc-section-5&quot;&gt;2.3.启动&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-6&quot; id=&quot;markdown-toc-section-6&quot;&gt;2.4.插件安装&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-7&quot; id=&quot;markdown-toc-section-7&quot;&gt;2.5.验证&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#kibana&quot; id=&quot;markdown-toc-kibana&quot;&gt;3. Kibana&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#section-8&quot; id=&quot;markdown-toc-section-8&quot;&gt;3.1.下载&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-9&quot; id=&quot;markdown-toc-section-9&quot;&gt;3.2.配置&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-10&quot; id=&quot;markdown-toc-section-10&quot;&gt;3.3.启动&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-11&quot; id=&quot;markdown-toc-section-11&quot;&gt;3.4.验证&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#elk&quot; id=&quot;markdown-toc-elk&quot;&gt;4.使ELK整体协作起来&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#section-12&quot; id=&quot;markdown-toc-section-12&quot;&gt;4.1.原理&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#el&quot; id=&quot;markdown-toc-el&quot;&gt;4.2.E和L的连接&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#kibana-1&quot; id=&quot;markdown-toc-kibana-1&quot;&gt;4.3.Kibana的配置&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#es-1&quot; id=&quot;markdown-toc-es-1&quot;&gt;4.4.ES&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#section-13&quot; id=&quot;markdown-toc-section-13&quot;&gt;5.小结&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;es是接触的比较早，在13年就做过相关开发，后来使用过ELK来做一些数据统计。最近打算从头来梳理一下这块的东西，今天就先从安装和配置开始吧。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;版本列表&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;project&lt;/th&gt;
      &lt;th&gt;version&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;es&lt;/td&gt;
      &lt;td&gt;2.3.4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;logstash&lt;/td&gt;
      &lt;td&gt;2.3.4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;kibana&lt;/td&gt;
      &lt;td&gt;4.5.3&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;logstash&quot;&gt;1.logstash配置&lt;/h2&gt;

&lt;h3 id=&quot;jdk&quot;&gt;1.1.Jdk安装&lt;/h3&gt;
&lt;p&gt;http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html&lt;/p&gt;

&lt;h3 id=&quot;logstash-1&quot;&gt;1.2.下载logstash&lt;/h3&gt;
&lt;p&gt;https://www.elastic.co/downloads/logstash&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;1.3.启动&lt;/h3&gt;

&lt;p&gt;解压后可直接启动，不增加额外的配置也是能够启动成功的。启动方式有多种，这里举例说明。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;使用-e指定启动的参数&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./logstash -e 'input { stdin { } } output { stdout {} }'
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里设定stdin为输入，stdout为输出。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;使用配置文件启动&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cat logstash-simple.conf
input { stdin { } }
output {
   stdout { codec=&amp;gt; rubydebug }
}

./logstash agent -f logstash-simple.conf
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-2&quot;&gt;1.4.验证&lt;/h3&gt;

&lt;p&gt;启动后才命令行输入”hello World”，如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;root@dt-vt-153:/opt/logstash/logstash-2.3.4/bin# ./logstash agent -f logstash-simple.conf

Settings: Default pipeline workers: 1
Pipeline main started
hello World
{
       &quot;message&quot; =&amp;gt; &quot;hello World&quot;,
       &quot;@version&quot; =&amp;gt; &quot;1&quot;,
       &quot;@timestamp&quot; =&amp;gt; &quot;2016-07-18T07:20:20.526Z&quot;,
       &quot;host&quot; =&amp;gt; &quot;0.0.0.0&quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;打印出来的message部分显示为输入内容。&lt;/p&gt;

&lt;h2 id=&quot;es&quot;&gt;2.ES&lt;/h2&gt;

&lt;h3 id=&quot;section-3&quot;&gt;2.1.下载&lt;/h3&gt;
&lt;p&gt;https://www.elastic.co/downloads/elasticsearch&lt;/p&gt;

&lt;h3 id=&quot;section-4&quot;&gt;2.2.配置&lt;/h3&gt;
&lt;p&gt;配置一下主机的地址,这里不配置的话，只能在安装服务的宿主机上使用localhost来访问ES了。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;vi config/elasticsearch.yml
network.host: 0.0.0.0
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-5&quot;&gt;2.3.启动&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/opt/elasticsearch/elasticsearch-2.3.4/bin/elasticsearch
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-6&quot;&gt;2.4.插件安装&lt;/h3&gt;

&lt;p&gt;kopf插件安装：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/opt/elasticsearch/elasticsearch-2.3.4/bin/plugin install lmenezes/elasticsearch-kopf
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;安装完之后，可以访问web页面http://[hostname]:9200/_plugin/kopf查看。&lt;/p&gt;

&lt;h3 id=&quot;section-7&quot;&gt;2.5.验证&lt;/h3&gt;

&lt;p&gt;es默认使用的9200端口，可使用下面的命令来查看该端口是否已经被监听：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;netstat -anp |grep :9200
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;或者使用浏览器访问端口9200.&lt;/p&gt;

&lt;h2 id=&quot;kibana&quot;&gt;3. Kibana&lt;/h2&gt;

&lt;h3 id=&quot;section-8&quot;&gt;3.1.下载&lt;/h3&gt;
&lt;p&gt;https://www.elastic.co/downloads/kibana&lt;/p&gt;

&lt;h3 id=&quot;section-9&quot;&gt;3.2.配置&lt;/h3&gt;

&lt;p&gt;配置一下es的地址。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;vi config/kibana.yml

elasticsearch.url: &quot;http://[hostname]:9200&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里默认是使用ES的数据。&lt;/p&gt;

&lt;h3 id=&quot;section-10&quot;&gt;3.3.启动&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/opt/kibana/kibana-4.5.3-linux-x64/bin/kibana
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-11&quot;&gt;3.4.验证&lt;/h3&gt;

&lt;p&gt;访问：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;http://[hostname]:5601/
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;点击”create”创建索引名称。&lt;/p&gt;

&lt;h2 id=&quot;elk&quot;&gt;4.使ELK整体协作起来&lt;/h2&gt;

&lt;h3 id=&quot;section-12&quot;&gt;4.1.原理&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;logstash&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;logstash主要用作收集数据使用，可以自由的定义数据的入口和出口，兼容多种数据源。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;elasticsearch&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;es和solr比较类似，都是基于lucene的来提供的搜索服务。但是在高并发的表现上，ES的负载均衡效果是优于solr的。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;kibana&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;kibana是一个可以可以用来查看ES里数据的Web。在早期logstash有一个logstash-web，但是功能比较简单。咱们这里说的kibana严格意义上说是kibana4，是在2015年重构完成的一个版本。&lt;/p&gt;

&lt;h3 id=&quot;el&quot;&gt;4.2.E和L的连接&lt;/h3&gt;
&lt;p&gt;其实就是把logstash收集到的数据写入es中，这里只要在logstash的启动参数上做配置就可以了，具体的配置文件如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;vi logstash-indexer.conf

input {
  file {
    type =&amp;gt;&quot;syslog&quot;
    path =&amp;gt; [ &quot;/var/log/syslog&quot; ]
  }
  syslog {
    type =&amp;gt;&quot;syslog&quot;
    port =&amp;gt;&quot;5544&quot;
  }
}
output {
  stdout { codec=&amp;gt; rubydebug }
  elasticsearch {hosts =&amp;gt; &quot;localhost&quot; }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;配置介绍&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;logstash的配置里，一定要有一个input和一个output。
file: 这里配置输入的文件信息。
syslog：把logstash配置为一个可接收syslog服务器来接收file里变化的数据。
output里定义了两处输出，分别是&lt;strong&gt;stdout&lt;/strong&gt;命令行和&lt;strong&gt;elasticsearch&lt;/strong&gt;。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;启动&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;nohup ./logstash agent -f logstash-indexer.conf &amp;gt; nohup &amp;amp;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;kibana-1&quot;&gt;4.3.Kibana的配置&lt;/h3&gt;
&lt;p&gt;只需要修改kibana.yml中es的地址就可以了。&lt;/p&gt;

&lt;h3 id=&quot;es-1&quot;&gt;4.4.ES&lt;/h3&gt;
&lt;p&gt;ES在这个架构中作为数据存储和索引的系统。无额外的特殊配置。&lt;/p&gt;

&lt;h3 id=&quot;section-13&quot;&gt;5.小结&lt;/h3&gt;
&lt;p&gt;ELK架构在处理运维系统的日志分析以及一些数据量不是很大的场景还是很实用的。快速、简单、易扩展，企业中使用可以考虑使用hdfs作为es的数据存储来使用，具体性能需要根据实际的业务复杂度来衡量，复杂度不是很高的海量数据统计，可优先考虑使用elk方案。&lt;/p&gt;

&lt;p&gt;参考地址：
http://baidu.blog.51cto.com/71938/1676798
https://www.gitbook.com/book/chenryn/kibana-guide-cn/details&lt;/p&gt;

</description>
        <pubDate>Wed, 20 Jul 2016 00:00:00 +0800</pubDate>
        <link>http://leocook.github.io/2016/07/20/ELK%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E4%BB%8B%E7%BB%8D/</link>
        <guid isPermaLink="true">http://leocook.github.io/2016/07/20/ELK%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E4%BB%8B%E7%BB%8D/</guid>
        
        <category>es</category>
        
        <category>logstash</category>
        
        <category>kibana</category>
        
        <category>ELK</category>
        
        
        <category>ELK</category>
        
      </item>
    
      <item>
        <title>Tez系列第三篇 Tez和oozie整合</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#section&quot; id=&quot;markdown-toc-section&quot;&gt;1.完成上一篇的基础的相关配置&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#tezjarooziehdfs&quot; id=&quot;markdown-toc-tezjarooziehdfs&quot;&gt;2.拷贝Tez的依赖Jar包到OOZIE的HDFS共享目录下&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#jar&quot; id=&quot;markdown-toc-jar&quot;&gt;3.修改Jar的权限&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#section-1&quot; id=&quot;markdown-toc-section-1&quot;&gt;4.是配置生效&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#workflowtez&quot; id=&quot;markdown-toc-workflowtez&quot;&gt;5.在workflow里使用Tez&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#workflowhivetez&quot; id=&quot;markdown-toc-workflowhivetez&quot;&gt;5.1.使单个workflow里的hive都用tez&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#workflowhivetez-1&quot; id=&quot;markdown-toc-workflowhivetez-1&quot;&gt;5.2.使单个workflow里的单个hive都用tez&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section&quot;&gt;1.完成上一篇的基础的相关配置&lt;/h2&gt;

&lt;h2 id=&quot;tezjarooziehdfs&quot;&gt;2.拷贝Tez的依赖Jar包到OOZIE的HDFS共享目录下&lt;/h2&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;hadoop fs -copyFromLocal *.jar /user/oozie/share/lib/lib_20150722203343/hive/
hadoop fs -copyFromLocal /usr/lib/tez/lib/*.jar /user/oozie/share/lib/lib_20150722203343/hive/
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;jar&quot;&gt;3.修改Jar的权限&lt;/h2&gt;
&lt;p&gt;保证oozie有权限读取、使用Jar包:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;hadoop fs -chown oozie:oozie /user/oozie/share/lib/lib_20150722203343/hive/*.jar
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;section-1&quot;&gt;4.是配置生效&lt;/h2&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;oozie admin -sharelibupdate
oozie admin -shareliblist hive
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;或者重启oozie也可以&lt;/p&gt;

&lt;h2 id=&quot;workflowtez&quot;&gt;5.在workflow里使用Tez&lt;/h2&gt;
&lt;p&gt;这里咱们只是让oozie处理hive作业时使用Tez引擎，具体配置如下.&lt;/p&gt;

&lt;h3 id=&quot;workflowhivetez&quot;&gt;5.1.使单个workflow里的hive都用tez&lt;/h3&gt;
&lt;p&gt;在作业流的hive-site.xml中加入下面的配置，即可使整个作业里的hive都使用Tez引擎：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;property&amp;gt;
	&amp;lt;name&amp;gt;hive.execution.engine&amp;lt;/name&amp;gt;
	&amp;lt;value&amp;gt;tez&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
	&amp;lt;name&amp;gt;tez.lib.uris&amp;lt;/name&amp;gt;
	&amp;lt;value&amp;gt;${nameNode}/tmp/apps/tez-0.8.2/,${nameNode}/tmp/apps/tez-0.8.2/lib&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
	&amp;lt;name&amp;gt;tez.use.cluster.hadoop-libs&amp;lt;/name&amp;gt;
	&amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;workflowhivetez-1&quot;&gt;5.2.使单个workflow里的单个hive都用tez&lt;/h3&gt;
&lt;p&gt;上面的配置不用加，在workflow.xml里的hive节点添加如下配置:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;property&amp;gt;
	&amp;lt;name&amp;gt;hive.execution.engine&amp;lt;/name&amp;gt;
	&amp;lt;value&amp;gt;tez&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
	&amp;lt;name&amp;gt;tez.lib.uris&amp;lt;/name&amp;gt;
	&amp;lt;value&amp;gt;${nameNode}/tmp/apps/tez-0.8.2/,${nameNode}/tmp/apps/tez-0.8.2/lib&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
	&amp;lt;name&amp;gt;tez.use.cluster.hadoop-libs&amp;lt;/name&amp;gt;
	&amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;hive.execution.engine属性可以不添加，在hive的脚本中的第一行添加:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;set hive.execution.engine=tez;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Tue, 17 May 2016 00:00:00 +0800</pubDate>
        <link>http://leocook.github.io/2016/05/17/Tez%E7%B3%BB%E5%88%97%E7%AC%AC%E4%B8%89%E7%AF%87-Tez%E5%92%8Coozie%E6%95%B4%E5%90%88/</link>
        <guid isPermaLink="true">http://leocook.github.io/2016/05/17/Tez%E7%B3%BB%E5%88%97%E7%AC%AC%E4%B8%89%E7%AF%87-Tez%E5%92%8Coozie%E6%95%B4%E5%90%88/</guid>
        
        <category>hadoop</category>
        
        <category>tez</category>
        
        <category>oozie</category>
        
        <category>hive</category>
        
        
        <category>tez</category>
        
      </item>
    
  </channel>
</rss>
