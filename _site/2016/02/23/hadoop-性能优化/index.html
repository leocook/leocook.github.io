<!DOCTYPE html>
<html>

  <head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Hadoop 性能优化</title>
	<meta name="description" content="从CSDN到博客园，到wordpress，再到jekyll。就是爱折腾.jekyll玩的还不是很熟，感兴趣的朋友可以多多交流哈!http://blog.leocook.org/ 另外，我建了个QQ群：305994766，希望对大数据、算法研发、系统架构感兴趣的朋友能够加入进来，大家一起学习，共同进步（进群请说明自...">
	
	<link rel="canonical" href="/2016/02/23/hadoop-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/">
	<link rel="alternate" type="application/rss+xml" title="跨界的IT博客 | hadoop | 大数据 | storm | mahout | spark" href="/feed.xml" />
	
	<!-- <link rel="stylesheet" href="/css/main.css"> -->
    
    <link rel="stylesheet" type="text/css" href="/static/css/bootstrap.min.css">
    <link rel="stylesheet" type="text/css" href="/static/css/index.css">
	<script type="text/javascript" src="/static/js/jquery-1.11.1.min.js"></script>
	<script type="text/javascript" src="/static/js/bootstrap.min.js"></script>
    <link rel="stylesheet" type="text/css" href="/static/css/monokai_sublime.min.css">
	<script type="text/javascript" src="/static/js/highlight.min.js"></script>

    <!--
    <link rel="stylesheet" type="text/css" href="http://apps.bdimg.com/libs/bootstrap/3.3.0/css/bootstrap.min.css">
	<script type="text/javascript" src="http://apps.bdimg.com/libs/jquery/2.1.1/jquery.min.js"></script>
	<script type="text/javascript" src="http://apps.bdimg.com/libs/bootstrap/3.3.0/js/bootstrap.min.js"></script>
    <link rel="stylesheet" type="text/css" href="http://apps.bdimg.com/libs/highlight.js/8.4/styles/monokai_sublime.min.css">
	<script type="text/javascript" src="http://apps.bdimg.com/libs/highlight.js/8.4/highlight.min.js"></script>
    -->
    
	<script type="text/javascript" src="/static/js/index.js"></script>
	<script>hljs.initHighlightingOnLoad();</script>
</head>

 <!--  <body data-spy="scroll" data-target="#myAffix"> -->
  <body>

    <header>

<!-- navbar -->
  <nav class="navbar navbar-inverse">
  <div class="container">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="/">跨界的IT博客 | hadoop | 大数据 | storm | mahout | spark</a>
      <p class="navbar-text"></p>
    </div>
    <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
      <ul class="nav navbar-nav navbar-right">

        
          <li>
        
        <a href="/">Home</a></li>

        
          
        
          
        
      </ul>
    </div><!-- /.navbar-collapse -->
  </div><!-- /.container-fluid -->
</nav>

</header>

    <div id="main" class="container main">
      <div class="row">
  <div id="myArticle" class="col-sm-9">
    <div class="post-area post">
      <header>
        <h1>Hadoop 性能优化</h1>
        <p>Feb 23, 2016</p>
      </header>
      <hr>
      <article>
        <p>从CSDN到博客园，到wordpress，再到jekyll。就是爱折腾.jekyll玩的还不是很熟，感兴趣的朋友可以多多交流哈!http://blog.leocook.org/ <br />
另外，我建了个QQ群：305994766，希望对大数据、算法研发、系统架构感兴趣的朋友能够加入进来，大家一起学习，共同进步（进群请说明自己的公司-职业-昵称）。</p>

<h2 id="section">1.应用程序角度进行优化</h2>

<h3 id="reduce">1.1.减少不必要的reduce任务</h3>
<p>若对于同一份数据需要多次处理，可以尝试先排序、分区，然后自定义InputSplit将某一个分区作为一个Map的输入，在Map中处理数据，将Reduce的个数设置为空。</p>

<h3 id="section-1">1.2.外部文件引用</h3>
<p>如字典、配置文件等需要在Task之间共享的数据，可使用分布式缓存DistributedCache或者使用-files</p>

<h3 id="combiner">1.3.使用Combiner</h3>
<p>combiner是发生在map端的，作用是归并Map端输出的文件，这样Map端输出的数据量就小了，减少了Map端和reduce端间的数据传输。需要注意的是，Combiner不能影响作业的结果;不是每个MR都可以使用Combiner的，需要根据具体业务来定;Combiner是发生在Map端的，不能垮Map来执行（只有Reduce可以接收多个Map任务的输出数据）</p>

<h3 id="writable">1.4.使用合适的Writable类型</h3>
<p>尽可能使用二进制的Writable类型，例如：IntWritable， FloatWritable等，而不是Text。因为在一个批处理系统中将数值转换为文本时低效率的。使用二进制的Writable类型可以降低cpu资源的消耗，也可以减少Map端中间数据、结果数据占用的空间。</p>

<h3 id="java">1.5.尽可能的少创建新的Java对象</h3>
<p>a)需要注意的Writable对象，例如下面的写法：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>public void map(...) {
…
for (String word : words) {
    output.collect(new Text(word), new IntWritable(1));
} }
</code></pre>
</div>

<p>这样会冲去创建对象new Text(word)和new IntWritable(1))，这样可能会产生海量的短周期对象。更高效的写法见下：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>class MyMapper … {
Text wordText = new Text();
IntWritable one = new IntWritable(1);
public void map(...) {
    for (String word: words) {
    wordText.set(word);
        output.collect(wordText, one);
    }
} }
</code></pre>
</div>

<p>b)对于可变字符串，使用StringBuffer而不是String</p>

<p>String类是经过final修饰的，那么每次对它的修改都会产生临时对象，而SB则不会。</p>

<h2 id="linux">2. Linux系统层面上的配置调优</h2>

<h3 id="section-2">2.1. 文件系统的配置</h3>
<p>a) 关闭文件在被操作时会记下时间戳:noatime和nodiratime <br />
b) 选择I/O性能较好的文件系统（Hadoop比较依赖本地的文件系统）</p>

<h3 id="linux-1">2.2. Linux文件系统预读缓冲区大小</h3>
<p>命令:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>blockdev
</code></pre>
</div>

<h3 id="raidlvm">2.3. 去除RAID和LVM</h3>

<h3 id="section-3">2.4. 增大同时打开的文件数和网络连接数</h3>
<p>ulimit net.core.somaxconn</p>

<div class="highlighter-rouge"><pre class="highlight"><code>ulimit net.core.somaxconn
</code></pre>
</div>

<h3 id="swap">2.5. 关闭swap分区</h3>
<p>在Hadoop中，对于每个作业处理的数据量和每个Task中用到的各种缓冲，用户都是完全可控的。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>/etc/sysctl.conf
</code></pre>
</div>

<h3 id="io">2.6. I/O调度器选择</h3>
<p>详情见AMD的白皮书</p>

<h2 id="hadoop">3. Hadoop平台内参数调优</h2>
<p>Hadoop相关可配置参数共有几百个，但是其中只有三十个左右会对其性能产生显著影响。</p>

<h3 id="section-4">3.1. 计算资源优化</h3>
<p>a) 设置合理的slot（资源槽位）</p>

<div class="highlighter-rouge"><pre class="highlight"><code>mapred.tasktracker.map.tasks.maximum / mapred.tasktracker.reduce.tasks.maximum
</code></pre>
</div>

<p>参数说明：每个TaskTracker上可并发执行的Map Task和Reduce Task数目 <br />
默认值：都是2 <br />
推荐值：根据具体的节点资源来看，推荐值是(core_per_node)/2~2*(cores_per_node) <br />
单位：无</p>

<h3 id="section-5">3.2. 节点间的通信优化</h3>
<p><strong>a) TaskTracker和JobTracker之间的心跳间隔</strong> <br />
这个值太小的话，在一个大集群中会造成JobTracker需要处理高并发心跳，可能会有很大的压力。 <br />
建议集群规模小于300时，使用默认值3秒，在此基础上，集群规模每增加100台，会加1秒。 <br />
<strong>b) 启用带外心跳(out-of-band heartbeat)</strong></p>

<div class="highlighter-rouge"><pre class="highlight"><code>mapreduce.tasktracker.outofband.heartbeat
</code></pre>
</div>

<p>参数说明：主要是为了减少任务分配延迟。它与常规心跳不同，一般的心跳是一定时间间隔发送的，而带外心跳是在任务运行结束或是失败时发送，这样就能在TaskTracker节点出现空闲资源的时候能第一时间通知JobTracker。</p>

<h3 id="section-6">3.3. 磁盘块的配置优化</h3>
<p>a) 作业相关的磁盘配置</p>

<div class="highlighter-rouge"><pre class="highlight"><code>mapred.local.dir
</code></pre>
</div>

<p>参数说明：map本地计算时所用到的目录，建议配置在多块硬盘上 <br />
b) 存储相关的磁盘配置（HDFS数据存储） <br />
dfs.data.dir <br />
参数说明：HDFS的数据存储目录，建议配置在多块硬盘上，可提高整体IO性能 <br />
例如：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>&lt;property&gt;
 &lt;name&gt;dfs.name.dir&lt;/name&gt;
 &lt;value&gt;/data1/hadoopdata/mapred/jt/,/data2/hadoopdata/mapred/jt/&lt;/value&gt;
&lt;/property&gt;
</code></pre>
</div>

<p>c) 存储相关的磁盘配置（HDFS元数据存储）</p>

<div class="highlighter-rouge"><pre class="highlight"><code>dfs.name.dir
</code></pre>
</div>

<p>参数说明：HDFS的元数据存储目录，建议设置多目录，每个多目录都可保存元数据的一个备份 <br />
注：要想提升hadoop整体IO性能，对于hadoop中用到的所有文件目录，都需要评估它磁盘IO的负载，对于IO负载可能会高的目录，最好都配置到多个磁盘上，以提示IO性能</p>

<h3 id="rpc-handlerhttp">3.4. RPC Handler个数和Http线程数优化</h3>
<p>a) RPC Handler个数</p>

<div class="highlighter-rouge"><pre class="highlight"><code>mapred.job.tracker.handler.count
</code></pre>
</div>

<p>参数说明：JobTracker需要并发的处理来自各个TaskTracker的RPC请求，可根据集群规模和并发数来调整RPC Handler的个数。 <br />
默认值：10 <br />
推荐值：60-70，最少要是TaskTracker个数的4% <br />
单位：无 <br />
b) Http线程数
   <br />
tasktracker.http.threads</p>

<p>在Shuffle阶段，Reduce Task会通过Http请求从各个TaskTracker上读取Map Task的结果，TaskTracker是使用Jetty Server来提供服务的，这里可适量调整Jetty Server的工作线程以提高它的并发处理能力。 <br />
默认值：40 <br />
推荐值：50-80+</p>

<h3 id="section-7">3.5. 选择合适的压缩算法</h3>
<div class="highlighter-rouge"><pre class="highlight"><code>mapred.compress.map.output / Mapred.output.compress
</code></pre>
</div>

<p>map输出的中间结果时需要进行压缩的，指定压缩方式<strong>（Mapred.compress.map.output.codec/ Mapred.output.compress.codec）</strong>。推荐使用LZO压缩。</p>

<h3 id="section-8">3.6. 启用批量任务调度(现在新版本都默认支持了)</h3>
<p>a) Fair Scheduler</p>

<div class="highlighter-rouge"><pre class="highlight"><code>mapred.fairscheduler.assignmultiple
</code></pre>
</div>

<p>b) Capacity Scheduler</p>

<h3 id="apache">3.7. 启用预读机制(Apache暂时没有)</h3>
<p>Hadoop是顺序读，所以预读机制可以很明显的提高HDFS的读性能。
HDFS预读：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>dfs.datanode.readahead ：true
dfs.datanode.readahead.bytes ：4MB
</code></pre>
</div>

<p>shuffle预读</p>

<div class="highlighter-rouge"><pre class="highlight"><code>mapred.tasktracker.shuffle.fadvise : true
mapred.tasktracker.shuffle.readahead.bytes : 4MB
</code></pre>
</div>

<h3 id="hdfs">3.8.HDFS相关参数优化</h3>
<p>1) dfs.replication <br />
参数说明：hdfs文件副本数 <br />
默认值：3 <br />
推荐值：3-5（对于IO较为密集的场景可适量增大） <br />
单位：无 <br />
2) dfs.blocksize <br />
参数说明： <br />
默认值：67108864(64MB) <br />
推荐值：稍大型集群建议设为128MB(134217728)或256MB(268435456) <br />
单位：无 <br />
3) dfs.datanode.handler.count <br />
参数说明：DateNode上的服务线程数 <br />
默认值：10 <br />
推荐值： <br />
单位：无 <br />
4) fs.trash.interval <br />
参数说明：HDFS文件删除后会移动到垃圾箱，该参数时清理垃圾箱的时间 <br />
默认值：0 <br />
推荐值：1440(1day) <br />
单位：无 <br />
5) io.sort.factor <br />
参数说明：当一个map task执行完之后，本地磁盘上(mapred.local.dir)有若干个spill文件，map task最后做的一件事就是执行merge sort，把这些spill文件合成一个文件（partition）。执行merge sort的时候，每次同时打开多少个spill文件由该参数决定。打开的文件越多，不一定merge sort就越快，所以要根据数据情况适当的调整。 <br />
默认值：10 <br />
推荐值： <br />
单位：无 <br />
6) mapred.child.java.opts <br />
参数说明：JVM堆的最大可用内存 <br />
默认值：-Xmx200m <br />
推荐值：-Xmx1G | -Xmx4G | -Xmx8G <br />
单位：-Xmx8589934592也行，单位不固定 <br />
7) io.sort.mb <br />
参数说明：Map Task的输出结果和元数据在内存中占的buffer总大小，当buffer达到一定阀值时，会启动一个后台进程来对buffer里的内容进行排序，然后写入本地磁盘，形成一个split小文件 <br />
默认值：100 <br />
推荐值：200 | 800 <br />
单位：兆 <br />
8) io.sort.spill.percent <br />
参数说明：即io.sort.mb中所说的阀值 <br />
默认值：0.8 <br />
推荐值：0.8 <br />
单位：无 <br />
9) io.sort.record <br />
参数说明：io.sort.mb中分类给元数据的空间占比 <br />
默认值：0.05 <br />
推荐值：0.05 <br />
单位：无 <br />
10) Mapred.reduce.parallel <br />
参数说明：Reduce shuffle阶段copier线程数。默认是5，对于较大集群，可调整为16~25 <br />
默认值：5 <br />
推荐值：16~25 <br />
单位：无</p>

<h2 id="section-9">4.系统实现角度调优</h2>
<p>https://www.xiaohui.org/archives/944.html</p>

<p>主要针对HDFS进行优化，HDFS性能低下的两个原因：调度延迟和可移植性</p>

<h3 id="section-10">4.1. 调度延迟</h3>
<p>关于调度延迟主要是发生在两个阶段： <br />
a) tasktracker上出现空余的slot到该tasktracker接收到新的task； <br />
b) tasktracker获取到了新的Task后，到连接上了datanode，并且可以读写数据。 <br />
之所以说这两个阶段不够高效，因为一个分布式计算系统需要解决的是计算问题，如果把过多的时间花费在其它上，就显得很不合适，例如线程等待、高负荷的数据传输。 <br />
下面解释下会经历上边两个阶段发生的过程： <br />
a) 当tasktracker上出现slot时，他会调用heartbeat方法向jobtracker发送心跳包（默认时间间隔是3秒，集群很大时可适量调整）来告知它，假设此时有准备需要执行的task，那么jobtracker会采用某种调度机制（调度机制很重要，是一个可以深度研究的东东）选择一个Task，然后通过调用heartbeat方法发送心跳包告知tasktracker。在该过程中，HDFS一直处于等待状态，这就使得资源利用率不高。 <br />
b) 这个过程中所发生的操作都是串行化的 <br />
tasktracker会连接到namenode上获取到自己需要的数据在datanode上的存储情况，然后再从datanode上读数据，在该过程中，HDFS一直处于等待状态，这就使得资源利用率不高。 <br />
若能减短hdfs的等待时间;在执行task之前就开始把数据读到将要执行该task的tasktracker上，减少数据传输时间，那么将会显得高效很多。未解决此类问题，有这样几种解决方案：重叠I/O和CPU阶段（pipelining），task预取（task prefetching），数据预取（data prefetching）等。</p>

<h3 id="section-11">4.2. 可移植性</h3>
<p>Hadoop是Java写的，所以可移植性相对较高。由于它屏蔽了底层文件系统，所以无法使用底层api来优化数据的读写。在活跃度较高的集群里（例如共享集群），大量并发读写会增加磁盘的随机寻道时间，这会降低读写效率;在大并发写的场景下，还会增加大量的磁盘碎片，这样将会大大的增加了读数据的成本，hdfs更适合文件顺序读取。
对于上述问题，可以尝试使用下面的解决方案：</p>

<blockquote>
  <p>tasktracker现在的线程模型是：one thread per client，即每个client连接都是由一个线程处理的（包括接受请求、处理请求，返回结果）。那么这一块一个拆分成两个部分来做，一组线程来处理和client的通信（Client Threads），一组用于数据的读写（Disk Threads）。</p>
</blockquote>

<p>想要解决上述两个问题，暂时没有十全十美的办法，只能尽可能的权衡保证调度延迟相对较低+可移植性相对较高。</p>

<h3 id="prefetchingpreshuffling">4.3. 优化策略：Prefetching与preshuffling</h3>
<ul>
  <li>
    <p>a) Prefetching包括Block-intra prefetching和Block-inter prefetching <br />
<strong>Block-intra prefetching：</strong>对block内部数据处理方式进行了优化，即一边进行计算，一边预读将要用到的数据。这种方式需要解决两个难题：一个是计算和预取同步，另一个是确定合适的预取率。前者可以使用进度条（processing bar）的概念，进度条主要是记录计算数据和预读数据的进度，当同步被打破时发出同步失效的通知。后者是要根据实际情况来设定，可采用重复试验的方法来确定。 <br />
<strong>Block-inter prefetching：</strong>在block层面上预读数据，在某个Task正在处理数据块A1的时候，预测器能预测接下来将要读取的数据块A2、A3、A4，然后把数据块A2、A3、A4预读到Task所在的rack上。</p>
  </li>
  <li>
    <p>b) preshuffling<br />
数据被map task处理之前，由预测器判断每条记录将要被哪个reduce task处理，将这些数据交给靠近reduce task的map task来处理。</p>
  </li>
</ul>

<p><strong>参考资料：</strong></p>

<ul>
  <li>cloudera官方文档 <br />
http://blog.cloudera.com/blog/2009/12/7-tips-for-improving-mapreduce-performance/</li>
  <li>
    <p>AMD白皮书(较为实用) <br />
http://www.admin-magazine.com/HPC/content/download/9408/73372/file/Hadoop_Tuning_Guide-Version5.pdf</p>
  </li>
  <li>国内博客（大部分内容都是AMD白皮书上的翻译）： <br />
http://dongxicheng.org/mapreduce/hadoop-optimization-0/
http://dongxicheng.org/mapreduce/hadoop-optimization-1/</li>
</ul>

      </article>
      <hr>
        <div class="bdsharebuttonbox">
            <a href="#" class="bds_more" data-cmd="more"></a>
            <a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
            <a href="#" class="bds_weixin" data-cmd="weixin" title="分享到微信"></a>
            <a href="#" class="bds_douban" data-cmd="douban" title="分享到豆瓣网"></a>
            <a href="#" class="bds_fbook" data-cmd="fbook" title="Share to Facebook"></a>
            <a href="#" class="bds_copy" data-cmd="copy" title="分享到复制网址"></a>
        </div>
        <script>
            window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"1","bdSize":"24"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
        </script>
    </div>
	
    <!-- duoshuo.com javascript include code. -->    
    
      <div class="post-area post comment">
        <div class="ds-thread" data-thread-key="/2016/02/23/hadoop-性能优化" data-title="Hadoop 性能优化" data-url="http://leocook.github.io/2016/02/23/hadoop-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"></div>
      </div>
	  <script type="text/javascript">
		var duoshuoQuery = {short_name:"leocook"};
		(function() {
		  var ds = document.createElement('script');
		  ds.type = 'text/javascript';ds.async = true;
		  ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		  ds.charset = 'UTF-8';
		  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(ds);
		})();
	  </script>
	
    <!-- disqus.com javascript include code. -->
	
    
  </div>
  
  <div id="content" class="col-sm-3">
    <!-- <div id="myAffix" class="shadow-bottom-center hidden-xs" data-spy="affix" data-offset-top="0" data-offset-bottom="-20"> -->
    <div id="myAffix" class="shadow-bottom-center hidden-xs" >
      <div class="categories-list-header">
        Content
      </div>
      <div class="content-text"></div>
    </div>
  </div>
  
</div>
    </div>

    
    <div id="top" data-toggle="tooltip" data-placement="left" title="back to top">
      <a href="javascript:;">
        <div class="arrow"></div>
        <div class="stick"></div>
      </a>
    </div>

    <footer class="">
  <div class="container">
    <div class="row">
      <div class="col-md-12">
        <a href="mailto:leocook@163.com"><span class="glyphicon glyphicon-envelope"></span> leocook@163.com</a>
        <span class="point"> · </span>
        
          <a href="https://github.com/leocook">
            <span class="icon">
              <svg viewBox="0 0 16 16">
                <path fill="#aaa" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
              </svg>
            </span>
            Github
            <!-- <span>leocook</span> -->
          </a>
          
          <span class="point"> · </span>
          <span><a href="https://github.com/leocook/leocook.github.io/blob/master/_posts/hadoop/2016-02-23-hadoop-性能优化.md">View source</a></span>
          <span class="point"> · </span>
          <span><a class="newpost" href="javascript:;">New post</a></span>
		  <span class="point"> · </span>
          <span><a href="/feed.xml">RSS</a></span>
          <span class="point"> · </span>
          <span>&copy; 2016 leocook</span>
      </div>
    </div>
  </div>
</footer>


    <script type="text/javascript">
    function OnClickNewPost()
    {
        var title = prompt("Please enter title of your post");
        if (title!=null){
            title = title.replace(" ", "-");
            var currentdate = new Date();
            var urlNewPage = "https://github.com/leocook/leocook.github.io/new/master?filename=_posts/" 
                + currentdate.getFullYear() + "-" + (currentdate.getMonth()+1) + "-" + currentdate.getDate() + "-" + title + ".md";
                
            var defaultText =  [
                '---',
                'layout: post',
                'comments: true',
                'categories: diary',
                '---',
                '## Title',
                'text'
                ].join('\n');
            urlNewPage += "&value=" + encodeURIComponent(defaultText);
            window.open(urlNewPage);
        }
    }
    
    $(function() {
      // CreateNewPostLinks
      $('.newpost').each(function(){
          $(this).click(OnClickNewPost);
      });
    });
</script>
  
  </body>
</html>
