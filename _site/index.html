<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>leocook</title>
    <meta name="description" content="">

    <link rel="shortcut icon" href="/favicon.ico?" type="image/x-icon">
    <link rel="icon" href="/favicon.ico?" type="image/x-icon">
    <link rel="stylesheet" href=" /css/fontawesome/css/font-awesome.min.css ">
    <link rel="stylesheet" href=" /css/main.css ">
    <link rel="canonical" href="http://leocook.github.io/">
    <link rel="alternate" type="application/rss+xml" title="leocook" href="http://leocook.github.io /feed.xml ">


    <script>
    // 百度统计代码
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?f1ad6f37c7565a0fbaf172ac83132650";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
    </script>


</head>


  <body>

    <header>
    <div class="wrapper">
        <a href="/" class="brand">leocook</a>
        <small>Big-Data Dev Engineer</small>
        <button id="headerMenu" class="menu"><i class="fa fa-bars"></i></button>
        <nav id="headerNav">
            <ul>
                <li>
                    
                    <a class="active" href="/">
                        
                        <i class="fa fa-home"></i>Home
                    </a>
                </li>

                
                    
                    <li>
                        
                        <a href="/archive/">
                        
                            <i class="fa fa-archive"></i>Archives
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/category/">
                        
                            <i class="fa fa-th-list"></i>Categories
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/tag/">
                        
                            <i class="fa fa-tags"></i>Tags
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/collection/">
                        
                            <i class="fa fa-bookmark"></i>Collections
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/about/">
                        
                            <i class="fa fa-heart"></i>About
                        </a>
                    </li>
                    
                
                    
                
                    
                
                    
                
                    
                
            </ul>
        </nav>
    </div>
</header>


        <div class="page clearfix" index>
    <div class="left">
        <h2>跨界的IT博客 | hadoop | 大数据 | spark</h2>
        <small>这里将会记录着我在互联网行业里走过的每一步。</small>
        <hr>
        <ul>
            
              <li>
                <h2>
                  <a class="post-link" href="/2016/07/23/%E4%BD%BF%E7%94%A8CM%E5%AE%89%E8%A3%85CDH%E5%8F%91%E8%A1%8C%E7%89%88%E7%9A%84Hadoop%E9%9B%86%E7%BE%A4/">使用cm安装cdh发行版的hadoop集群</a>
                </h2>
                <div class="label">
                    <div class="label-card">
                        <i class="fa fa-calendar"></i>2016-07-23
                    </div>
                    <div class="label-card">
                        
                    </div>
                    <div class="label-card">
                        
                    </div>

                    <div class="label-card">
                    


<!-- <span class="point">•</span> -->
<span class="categories">
  <i class="fa fa-th-list"></i>
  
    
        <a href="/category/#hadoop" title="Category: hadoop" rel="category">hadoop</a>
    
  

  <!-- <span class="point">•</span> -->
</span>


                    </div>

                    <div class="label-card">
                    
<!-- <span class="point">•</span> -->
<span class="pageTag">
  <i class="fa fa-tags"></i>
  
    
        <a href="/tag/#cm" title="Tag: cm" rel="tag">cm</a>&nbsp;
    
        <a href="/tag/#hadoop" title="Tag: hadoop" rel="tag">hadoop</a>
    
  

</span>

                    </div>
                </div>
                <div class="excerpt">
                    <ul id="markdown-toc">
  <li><a href="#cloudera-manager" id="markdown-toc-cloudera-manager">1.Cloudera Manager安装前准备</a>    <ul>
      <li><a href="#section" id="markdown-toc-section">1.1. 操作系统的优化</a></li>
      <li><a href="#section-1" id="markdown-toc-section-1">1.2. 数据的存放</a></li>
    </ul>
  </li>
  <li><a href="#cloudera-manager-1" id="markdown-toc-cloudera-manager-1">2.开始安装Cloudera Manager</a>    <ul>
      <li><a href="#cm" id="markdown-toc-cm">2.1.下载CM</a></li>
      <li><a href="#section-2" id="markdown-toc-section-2">2.2.配置私有软件仓库(如果不使用私有仓库，这里可以直接跳过)</a>        <ul>
          <li><a href="#section-3" id="markdown-toc-section-3">2.2.1.创建一个临时可以使用的远程仓库</a></li>
          <li><a href="#cm-1" id="markdown-toc-cm-1">2.2.2.配置安装CM所需要的私有仓库</a></li>
        </ul>
      </li>
      <li><a href="#cm-2" id="markdown-toc-cm-2">2.2.3.配置使用CM安装节点时会用到的仓库</a></li>
      <li><a href="#jdk" id="markdown-toc-jdk">2.2.4.配置节点的JDK</a></li>
      <li><a href="#cm-3" id="markdown-toc-cm-3">2.3.开始安装CM</a></li>
      <li><a href="#cm-4" id="markdown-toc-cm-4">2.4.使用CM安装集群</a></li>
    </ul>
  </li>
  <li><a href="#section-4" id="markdown-toc-section-4">3.注意事项</a>    <ul>
      <li><a href="#host" id="markdown-toc-host">3.1.主机的Host配置不能出差错</a></li>
      <li><a href="#cm-agent" id="markdown-toc-cm-agent">3.2.cm-agent安装失败重试时</a></li>
    </ul>
  </li>
  <li><a href="#section-5" id="markdown-toc-section-5">4.会用到的一些地址总结</a>    <ul>
      <li><a href="#mysql" id="markdown-toc-mysql">4.1.Mysql的相关配置</a></li>
      <li><a href="#section-6" id="markdown-toc-section-6">4.2.创建本地仓库</a></li>
      <li><a href="#parcel" id="markdown-toc-parcel">4.3.parcel的下载地址</a></li>
      <li><a href="#cm-5" id="markdown-toc-cm-5">4.4.cm的下载地址</a></li>
    </ul>
  </li>
</ul>

<p>对于Hadoop这个复杂的大系统，我们期望能有一个平台，可以对Hadoop的每一个部件都能够进行安装部署，以及细颗粒度的监控。Apache发行版的Hadoop可以使用Ambari；Cloudera公司的CDH版本Hadoop则可以使用Cloudera Manager（后面简称为CM）来统一管理和部署。咱们这里的操作系统使用的是ubuntu14.04.</p>

<h2 id="cloudera-manager">1.Cloudera Manager安装前准备</h2>

<h3 id="section">1.1. 操作系统的优化</h3>
<ul>
  <li>打开的最大文件数
修改当前的session配置(临时)：</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code>ulimit -SHn 65535
</code></pre>
</div>

<p>永久修改（需要重启服务器）：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>sudo echo "ulimit -SHn 65535" &gt;&gt; /etc/rc.local
sudo chmod +x /etc/rc.local
</code></pre>
</div>

<ul>
  <li>打开的组大文件句柄数
临时配置</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code># 一般可不做修改，这是临时配置
sudo echo 2000000 &gt; /proc/sys/fs/file-max
</code></pre>
</div>

<p>永久配置</p>

<div class="highlighter-rouge"><pre class="highlight"><code>echo "echo 2000000 &gt; /proc/sys/fs/file-max" &gt;&gt; /etc/rc.local
</code></pre>
</div>

<p>或者</p>

<div class="highlighter-rouge"><pre class="highlight"><code>sudo echo "fs.file-max = 2000000" &gt;&gt;/etc/sysctl.conf #推荐
#使文件生效sudo /sbin/sysctl -p
</code></pre>
</div>

<ul>
  <li>打开的最大网络连接数</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code>sudo echo "net.core.somaxconn = 2048" &gt;&gt;/etc/sysctl.conf
sudo /sbin/sysctl -p
</code></pre>
</div>

<ul>
  <li>关闭selinux</li>
</ul>

<p>ubuntu默认是不安装的selinux的，所以这里可以直接忽略。</p>

<ul>
  <li>配置ntp</li>
</ul>

<p>安装</p>

<div class="highlighter-rouge"><pre class="highlight"><code>apt-get install ntp
</code></pre>
</div>

<p>如果只需要保证集群内部的各个server之间时间保持同步，只需要在需要同步的机器上配置：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>0 */12 * * * ntpdate dt-vt-154
</code></pre>
</div>

<p>如果需要时间和互联网的时间保持一致，那么就需要在提供ntp server的机器上配置上层ntpserver:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>server [ntpserver_01]
server [ntpserver_02]
server [ntpserver_03]
</code></pre>
</div>

<ul>
  <li>关闭防火墙</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code>sudo ufw disable #关闭防火墙
apt-get remove iptables #卸载防火墙
</code></pre>
</div>

<ul>
  <li>配置好hosts映射文件</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code>vi /etc/hosts

192.168.1.151   dt-vt-151
192.168.1.152   dt-vt-152
192.168.1.153   dt-vt-153
192.168.1.154   dt-vt-154
</code></pre>
</div>

<ul>
  <li>Java环境配置</li>
</ul>

<p>安装</p>

<div class="highlighter-rouge"><pre class="highlight"><code>mkdir /opt/java
cd /opt/java
#下载到安装文件到这个目录
</code></pre>
</div>

<p>环境配置</p>

<div class="highlighter-rouge"><pre class="highlight"><code>vi /etc/profile

export JAVA_HOME=/opt/java/jdk1.7.0_79
export CLASSPATH=.:$JAVA_HOME/lib
export PATH=$JAVA_HOME/bin:$PATH
</code></pre>
</div>

<p>执行下面命令，使当前的session生效：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>source /etc/profile
</code></pre>
</div>

<h3 id="section-1">1.2. 数据的存放</h3>
<p>在使用CM来管理集群的时候，会涉及到大量的数据存储，例如Hadoop的主机列表信息，主机的配置信息，负载信息，各个模块的运行时状态等等。
咱们这里使用mysql来作为CM的数据存储，这里不仅是CM，Hadoop中的Hive等模块的元数据，都来使用mysql存储。</p>

<ul>
  <li>安装mysql</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code>sudo apt-get install mysql-server
</code></pre>
</div>

<p>我这里安装完后是5.5.49.</p>

<ul>
  <li>关闭mysql，备份配置文件</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code>/etc/init.d/mysql stop
</code></pre>
</div>

<p>把/var/lib/mysql/ib_logfile0和/var/lib/mysql/ib_logfile1拷贝至某个配置目录中，例如：/var/lib/mysql/bak</p>

<ul>
  <li>配置InnoDB引擎</li>
</ul>

<p>务必使用InnoDB引擎引擎，若是使用MyISAM引擎CM将启动不了。在Mysql的命令行中运行下面的命令，来查看你的Mysql使用了哪个引擎。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>mysql&gt; show table status;
</code></pre>
</div>

<ul>
  <li>配置mysql的innodb刷写模式</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code>innodb_flush_method=O_DIRECT
</code></pre>
</div>

<p>即：配置Innodb的刷写模式为异步写模式。</p>

<ul>
  <li>修改mysql的最大连接数</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code>max_connections=1550
</code></pre>
</div>

<p>在这里，你应该会考虑配置该数值为多少比较合适。
当集群规模<strong>小于50台</strong>的时候，假设该库中有N个数据库是用来服务于Hadoop的，那么max_connections可以设置为100*N+50。例如：Cloudera Manager Server, Activity Monitor, Reports Manager, Cloudera Navigator, 和 Hive metastore都是使用mysql的，那么就配置max_connections为550.
当集群规模<strong>大于50台</strong>的时候，建议每个数据库只存放在一台机器上。</p>

<ul>
  <li>配置文件样例</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code>[mysqld]
transaction-isolation = READ-COMMITTED
# Disabling symbolic-links is recommended to prevent assorted security risks;
# to do so, uncomment this line:
# symbolic-links = 0

key_buffer = 16M
key_buffer_size = 32M
max_allowed_packet = 32M
thread_stack = 256K
thread_cache_size = 64
query_cache_limit = 8M
query_cache_size = 64M
query_cache_type = 1

max_connections = 1550
#expire_logs_days = 10
#max_binlog_size = 100M


# InnoDB settings
innodb_file_per_table = 1
innodb_flush_log_at_trx_commit  = 2
innodb_log_buffer_size = 64M
innodb_buffer_pool_size = 4G
innodb_thread_concurrency = 8
innodb_flush_method = O_DIRECT
innodb_log_file_size = 512M

[mysqld_safe]
log-error=/var/log/mysqld.log
pid-file=/var/run/mysqld/mysqld.pid

</code></pre>
</div>

<ul>
  <li>启动mysql</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code>/etc/init.d/mysql start
</code></pre>
</div>

<p>打开开机自启</p>

<div class="highlighter-rouge"><pre class="highlight"><code>apt-get install sysv-rc-conf
sysv-rc-conf mysql on
</code></pre>
</div>

<ul>
  <li>安装mysql-jdbc驱动</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code>apt-get install libmysql-java
</code></pre>
</div>

<ul>
  <li>mysql远程连接</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code>vi /etc/mysql/my.cnf

bind-address = 0.0.0.0
</code></pre>
</div>

<ul>
  <li>給相关服务创建mysql的数据库</li>
</ul>

<p>相关列表如下：</p>

<table>
  <thead>
    <tr>
      <th>Role</th>
      <th>Database</th>
      <th>User</th>
      <th>Password</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Activity Monitor</td>
      <td>amon</td>
      <td>amon</td>
      <td>amon_password</td>
    </tr>
    <tr>
      <td>Reports Manager</td>
      <td>rman</td>
      <td>rman</td>
      <td>rman_password</td>
    </tr>
    <tr>
      <td>Hive Metastore Server</td>
      <td>hive_metastore</td>
      <td>hive</td>
      <td>hive_password</td>
    </tr>
    <tr>
      <td>Sentry Server</td>
      <td>sentry</td>
      <td>sentry</td>
      <td>sentry_password</td>
    </tr>
    <tr>
      <td>Cloudera Navigator Audit Server</td>
      <td>nav</td>
      <td>nav</td>
      <td>nav_password</td>
    </tr>
    <tr>
      <td>Cloudera Navigator Metadata Server</td>
      <td>navms</td>
      <td>navms</td>
      <td>navms_password</td>
    </tr>
    <tr>
      <td>OOZIE</td>
      <td>oozie</td>
      <td>oozie</td>
      <td>oozie</td>
    </tr>
  </tbody>
</table>

<p>建表语句格式如下：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>create database database DEFAULT CHARACTER SET utf8;
grant all on database.* TO 'user'@'%' IDENTIFIED BY 'password';
</code></pre>
</div>

<p>建表语句如下：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>create database amon DEFAULT CHARACTER SET utf8;
grant all on amon.* TO 'amon'@'%' IDENTIFIED BY 'amon';

create database rmon DEFAULT CHARACTER SET utf8;
grant all on rmon.* TO 'rmon'@'%' IDENTIFIED BY 'rmon';

create database hive_metastore DEFAULT CHARACTER SET utf8;
grant all on hive_metastore.* TO 'hive'@'%' IDENTIFIED BY 'hive';

create database sentry DEFAULT CHARACTER SET utf8;
grant all on sentry.* TO 'sentry'@'%' IDENTIFIED BY 'sentry';

create database nav DEFAULT CHARACTER SET utf8;
grant all on nav.* TO 'nav'@'%' IDENTIFIED BY 'nav';

create database navms DEFAULT CHARACTER SET utf8;
grant all on navms.* TO 'navms'@'%' IDENTIFIED BY 'navms';

create database oozie DEFAULT CHARACTER SET utf8;
grant all on oozie.* TO 'oozie'@'%' IDENTIFIED BY 'oozie';
</code></pre>
</div>

<h2 id="cloudera-manager-1">2.开始安装Cloudera Manager</h2>

<h3 id="cm">2.1.下载CM</h3>

<p>可以下载安装最新版本的CM：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>wget http://archive.cloudera.com/cm5/installer/latest/cloudera-manager-installer.bin
</code></pre>
</div>

<p>当然，如果你想选择安装其它版本，可以访问下面的地址，并选择下载你所需要的版本(cm5+)：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>http://archive.cloudera.com/cm5/installer/
</code></pre>
</div>

<p>我这里使用的是版本是5.4.10，从release note上看，目前cdh5.4.10是最稳当的版本。我下载到了本地路径如下：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>/opt/cm/cloudera-manager-installer.bin
</code></pre>
</div>

<p>修改权限，使其可以被执行：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>chmod u+x cloudera-manager-installer.bin
</code></pre>
</div>

<h3 id="section-2">2.2.配置私有软件仓库(如果不使用私有仓库，这里可以直接跳过)</h3>

<h4 id="section-3">2.2.1.创建一个临时可以使用的远程仓库</h4>
<p>这个配置是在安装cloudera-manager-server的时候才会用的。这里的仓库是使用传统的http协议，通过网络传输数据的。可以去http://archive.cloudera.com/cm5/repo-as-tarball/下载你所需要的cdh包。</p>

<ul>
  <li>解压安装包</li>
</ul>

<p>下载完安装包后，解压到某个目录下，我这里下载的是cm5.4.10-ubuntu14-04.tar.gz这个版本。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>tar -zxvf cm5.4.10-ubuntu14-04.tar.gz
chmod -R ugo+rX /opt/cm/local_resp/cm
</code></pre>
</div>

<p>解压后的目录是/opt/cm/local_resp/cm</p>

<ul>
  <li>启动Http server</li>
</ul>

<p>启动一个Http服务，使可以通过网络来访问仓库中的数据。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>cd /opt/cm/
python -m SimpleHTTPServer 8900
</code></pre>
</div>

<p>我这里使用的是8900，你可以根据需要，使用指定的端口。</p>

<ul>
  <li>验证</li>
</ul>

<p>可在浏览器中访问地址http://server:8900/cm，如果可以正常访问，并且能看到相对应的文件列表，则表示正常启动。</p>

<h4 id="cm-1">2.2.2.配置安装CM所需要的私有仓库</h4>

<p>在目录<strong>/etc/apt/sources.list.d/</strong>下创建文件<strong>my-private-cloudera-repo.list</strong>，并写入配置把这个文件和上面新建的仓库关联到一起：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>vi /etc/apt/sources.list.d/my-private-cloudera-repo.list

deb [arch=amd64] http://192.168.1.154:8900/cm/ trusty-cm5.4.10 contrib
</code></pre>
</div>

<p>执行下面的命令，使得上面的配置生效：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>sudo apt-get update
</code></pre>
</div>

<h3 id="cm-2">2.2.3.配置使用CM安装节点时会用到的仓库</h3>
<p>可以下载地址：http://archive.cloudera.com/cm5/ubuntu/trusty/amd64/cm/ 里的所有内容到本地，然后使用<strong>2.2.1</strong>中的方式来启动一个Http server。</p>

<h3 id="jdk">2.2.4.配置节点的JDK</h3>
<p>这一步是可选的，如果你不想每台机器都去手动安装，也可以在后边使用CM来批量安装。</p>

<h3 id="cm-3">2.3.开始安装CM</h3>
<ul>
  <li>连接互联网安装</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code>sudo ./cloudera-manager-installer.bin
</code></pre>
</div>

<p>或者</p>

<ul>
  <li>使用本地仓库安装</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code>sudo ./cloudera-manager-installer.bin --skip_repo_package=1
</code></pre>
</div>

<p>然后就是一路的YES &amp; NEXT，最后安装完成，CM默认的端口是7180，账户名和密码都是7180.</p>

<h3 id="cm-4">2.4.使用CM安装集群</h3>

<p>首次登陆CM管理界面的时候，会出现一个集群安装向导。我这里选择的是免费版本。然后大概有如下几步：</p>

<ul>
  <li>
    <p>使用ip或者hostname来搜索主机，搜索到之后，go to next step.</p>
  </li>
  <li>
    <p>看到如下图片的时候，如果你已经在前面的主机中安装好了JDK，那么这里可以不选，如果没有，则必须选择。</p>
  </li>
</ul>

<p><img src="http://7xriy2.com1.z0.glb.clouddn.com/cm-02.png" alt="CM JDK" title="cm jdk" /></p>

<ul>
  <li>选择是否使用单用户模式（Single User Mode）</li>
</ul>

<p>不使用该模式的话，HDFS服务会使用“hdfs”账户来启动，Hbase的Region Server会使用“hbase”账户来启动。使用了该模式之后，所有的服务都是使用同一个账户去启动的。
这里主要看集群的使用场景，如果其中涉及到不同的模块是由不同人员来运维管理的话，我建议还是不要使用单用户模式了。但如果集群是统一由一个人员来管理，那么选择使用单用户模式可能会方便很多。
我这里没有使用单用户模式。</p>

<ul>
  <li>配置好SSH登录</li>
</ul>

<p><img src="http://7xriy2.com1.z0.glb.clouddn.com/cm-03.png" alt="配置ssh登录信息" title="输入密码" /></p>

<ul>
  <li>
    <p>配置好SSH后开始连入主机，安装jdk和cm-agent
<img src="http://7xriy2.com1.z0.glb.clouddn.com/cm-04.png" alt="install cm agent" title="install cm agent" /></p>
  </li>
  <li>
    <p>安装完成，此时cm-agent就已经安装好了，随时都可以使用cm-server控制安装Hadoop的相关组件,完成后先不要点击进入下一步，继续看下面。
<img src="http://7xriy2.com1.z0.glb.clouddn.com/cm-05.png" alt="cm agent ok" title="cm agent ok" /></p>
  </li>
  <li>
    <p>分发Hadoop的安装包</p>
  </li>
</ul>

<p>去地址：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>http://archive.cloudera.com/cdh5/parcels/5.4.10/
</code></pre>
</div>

<p>下载：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>CDH-5.4.10-1.cdh5.4.10.p0.16-trusty.parcel
CDH-5.4.10-1.cdh5.4.10.p0.16-trusty.parcel.sha1
manifest.json
</code></pre>
</div>

<p>下载完成后：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>把"CDH-5.4.10-1.cdh5.4.10.p0.16-trusty.parcel.sha1"重命名为"CDH-5.4.10-1.cdh5.4.10.p0.16-trusty.parcel.sha"
</code></pre>
</div>

<p>并移到目录：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>/opt/cloudera/parcel-repo
</code></pre>
</div>

<p>然后在cm-serve点击进入下一页，将会看到如下图：
<img src="http://7xriy2.com1.z0.glb.clouddn.com/cm-06.png" alt="cm parcel distributed" title="cm parcel distributed" />
因为你已经把安装包下载好，并且放入到/opt/cloudera/parcel-repo（默认的目录）里面，所以这里的<strong>Download</strong>自然就是100%，<strong>Distributed</strong>是把安装包从cm-server往集群中各个节点分发的过程，<strong>Unpacked</strong>是表示各个节点的上安装包的解压情况进度，前面都OK后，<strong>Activated</strong>自然就可以了，表示安装包已经部署好了，可以随时进行安装。</p>

<ul>
  <li>
    <p>选择安装Hadoop的那些组件之后，会在这里显示各个组件部署的主机地址。
<img src="http://7xriy2.com1.z0.glb.clouddn.com/cm-07.png" alt="hosts choose" title="hosts choose" /></p>
  </li>
  <li>
    <p>这里配置的是一些组件使用的mysql信息：
<img src="http://7xriy2.com1.z0.glb.clouddn.com/cm-08.png" alt="hadoop mysql config" title="hadoop mysql config" /></p>
  </li>
  <li>
    <p>然后可以配置一些服务的的具体参数
<img src="http://7xriy2.com1.z0.glb.clouddn.com/cm-09.png" alt="hadoop config" title="hadoop config" /></p>
  </li>
  <li>
    <p>参数配置都没问题后，开始执行安装。
<img src="http://7xriy2.com1.z0.glb.clouddn.com/cm-10.png" alt="hadoop install" title="hadoop install" /></p>
  </li>
  <li>
    <p>安装完成后。
<img src="http://7xriy2.com1.z0.glb.clouddn.com/cm-11.jpeg" alt="install success" title="install success" />
PS：我这里的Kafka是后来安装上去的，默认Hadoop的parcel包是没有kafka的。</p>
  </li>
</ul>

<h2 id="section-4">3.注意事项</h2>

<h3 id="host">3.1.主机的Host配置不能出差错</h3>
<p>我就配置错过host，期间走了一些弯路，主要表现在添加完主机之后，Hosts下的主机名都是localhost。</p>

<h3 id="cm-agent">3.2.cm-agent安装失败重试时</h3>
<p>如果在重试的过程中出现了一直等待，或者cm-agent端口被占用的情况，大概有下面的几种情况：</p>

<ul>
  <li>锁文件没有删除</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code>sudo rm /tmp/.scm_prepare_node.lock
</code></pre>
</div>

<ul>
  <li>端口被占用 <strong>9000/9001</strong></li>
</ul>

<p>这种情况是部分进程没有关闭成功，找到端口对应的进程号，然后然后使用<strong>kill -9停止进程</strong></p>

<div class="highlighter-rouge"><pre class="highlight"><code>netstat -nap | grep 9000
netstat -nap | grep 9001
</code></pre>
</div>

<p>主要是<strong>supervisor</strong>和<strong>cm-agent</strong>进程</p>

<h2 id="section-5">4.会用到的一些地址总结</h2>

<h3 id="mysql">4.1.Mysql的相关配置</h3>
<p>http://www.cloudera.com/documentation/enterprise/5-4-x/topics/cm_ig_mysql.html</p>

<h3 id="section-6">4.2.创建本地仓库</h3>

<ul>
  <li>For CM</li>
</ul>

<p>http://www.cloudera.com/documentation/enterprise/5-4-x/topics/cm_ig_create_local_package_repo.html</p>

<ul>
  <li>For parcel</li>
</ul>

<p>http://www.cloudera.com/documentation/enterprise/5-4-x/topics/cm_ig_create_local_parcel_repo.html</p>

<h3 id="parcel">4.3.parcel的下载地址</h3>

<p>http://archive.cloudera.com/cdh5/parcels/
http://archive.cloudera.com/kafka/parcels/</p>

<h3 id="cm-5">4.4.cm的下载地址</h3>

<p>加压后可以直接运行
http://archive.cloudera.com/cm5/cm/5/</p>

                </div>
                <div class="read-all">
                    <a  href="/2016/07/23/%E4%BD%BF%E7%94%A8CM%E5%AE%89%E8%A3%85CDH%E5%8F%91%E8%A1%8C%E7%89%88%E7%9A%84Hadoop%E9%9B%86%E7%BE%A4/"><i class="fa fa-newspaper-o"></i>Read All</a>
                </div>
                <hr>
              </li>
            
              <li>
                <h2>
                  <a class="post-link" href="/2016/07/20/ELK%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E4%BB%8B%E7%BB%8D/">Elk安装配置介绍</a>
                </h2>
                <div class="label">
                    <div class="label-card">
                        <i class="fa fa-calendar"></i>2016-07-20
                    </div>
                    <div class="label-card">
                        
                    </div>
                    <div class="label-card">
                        
                    </div>

                    <div class="label-card">
                    


<!-- <span class="point">•</span> -->
<span class="categories">
  <i class="fa fa-th-list"></i>
  
    
        <a href="/category/#ELK" title="Category: ELK" rel="category">ELK</a>
    
  

  <!-- <span class="point">•</span> -->
</span>


                    </div>

                    <div class="label-card">
                    
<!-- <span class="point">•</span> -->
<span class="pageTag">
  <i class="fa fa-tags"></i>
  
    
        <a href="/tag/#es" title="Tag: es" rel="tag">es</a>&nbsp;
    
        <a href="/tag/#logstash" title="Tag: logstash" rel="tag">logstash</a>&nbsp;
    
        <a href="/tag/#kibana" title="Tag: kibana" rel="tag">kibana</a>&nbsp;
    
        <a href="/tag/#ELK" title="Tag: ELK" rel="tag">ELK</a>
    
  

</span>

                    </div>
                </div>
                <div class="excerpt">
                    <ul id="markdown-toc">
  <li><a href="#section" id="markdown-toc-section">版本列表</a></li>
  <li><a href="#logstash" id="markdown-toc-logstash">1.logstash配置</a>    <ul>
      <li><a href="#jdk" id="markdown-toc-jdk">1.1.Jdk安装</a></li>
      <li><a href="#logstash-1" id="markdown-toc-logstash-1">1.2.下载logstash</a></li>
      <li><a href="#section-1" id="markdown-toc-section-1">1.3.启动</a></li>
      <li><a href="#section-2" id="markdown-toc-section-2">1.4.验证</a></li>
    </ul>
  </li>
  <li><a href="#es" id="markdown-toc-es">2.ES</a>    <ul>
      <li><a href="#section-3" id="markdown-toc-section-3">2.1.下载</a></li>
      <li><a href="#section-4" id="markdown-toc-section-4">2.2.配置</a></li>
      <li><a href="#section-5" id="markdown-toc-section-5">2.3.启动</a></li>
      <li><a href="#section-6" id="markdown-toc-section-6">2.4.插件安装</a></li>
      <li><a href="#section-7" id="markdown-toc-section-7">2.5.验证</a></li>
    </ul>
  </li>
  <li><a href="#kibana" id="markdown-toc-kibana">3. Kibana</a>    <ul>
      <li><a href="#section-8" id="markdown-toc-section-8">3.1.下载</a></li>
      <li><a href="#section-9" id="markdown-toc-section-9">3.2.配置</a></li>
      <li><a href="#section-10" id="markdown-toc-section-10">3.3.启动</a></li>
      <li><a href="#section-11" id="markdown-toc-section-11">3.4.验证</a></li>
    </ul>
  </li>
  <li><a href="#elk" id="markdown-toc-elk">4.使ELK整体协作起来</a>    <ul>
      <li><a href="#section-12" id="markdown-toc-section-12">4.1.原理</a></li>
      <li><a href="#el" id="markdown-toc-el">4.2.E和L的连接</a></li>
      <li><a href="#kibana-1" id="markdown-toc-kibana-1">4.3.Kibana的配置</a></li>
      <li><a href="#es-1" id="markdown-toc-es-1">4.4.ES</a></li>
      <li><a href="#section-13" id="markdown-toc-section-13">5.小结</a></li>
    </ul>
  </li>
</ul>

<p>es是接触的比较早，在13年就做过相关开发，后来使用过ELK来做一些数据统计。最近打算从头来梳理一下这块的东西，今天就先从安装和配置开始吧。</p>

<h2 id="section">版本列表</h2>

<table>
  <thead>
    <tr>
      <th>project</th>
      <th>version</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>es</td>
      <td>2.3.4</td>
    </tr>
    <tr>
      <td>logstash</td>
      <td>2.3.4</td>
    </tr>
    <tr>
      <td>kibana</td>
      <td>4.5.3</td>
    </tr>
  </tbody>
</table>

<h2 id="logstash">1.logstash配置</h2>

<h3 id="jdk">1.1.Jdk安装</h3>
<p>http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html</p>

<h3 id="logstash-1">1.2.下载logstash</h3>
<p>https://www.elastic.co/downloads/logstash</p>

<h3 id="section-1">1.3.启动</h3>

<p>解压后可直接启动，不增加额外的配置也是能够启动成功的。启动方式有多种，这里举例说明。</p>

<ul>
  <li>使用-e指定启动的参数</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code>./logstash -e 'input { stdin { } } output { stdout {} }'
</code></pre>
</div>

<p>这里设定stdin为输入，stdout为输出。</p>

<ul>
  <li>使用配置文件启动</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code>cat logstash-simple.conf
input { stdin { } }
output {
   stdout { codec=&gt; rubydebug }
}

./logstash agent -f logstash-simple.conf
</code></pre>
</div>

<h3 id="section-2">1.4.验证</h3>

<p>启动后才命令行输入”hello World”，如下：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>root@dt-vt-153:/opt/logstash/logstash-2.3.4/bin# ./logstash agent -f logstash-simple.conf

Settings: Default pipeline workers: 1
Pipeline main started
hello World
{
       "message" =&gt; "hello World",
       "@version" =&gt; "1",
       "@timestamp" =&gt; "2016-07-18T07:20:20.526Z",
       "host" =&gt; "0.0.0.0"
}
</code></pre>
</div>

<p>打印出来的message部分显示为输入内容。</p>

<h2 id="es">2.ES</h2>

<h3 id="section-3">2.1.下载</h3>
<p>https://www.elastic.co/downloads/elasticsearch</p>

<h3 id="section-4">2.2.配置</h3>
<p>配置一下主机的地址,这里不配置的话，只能在安装服务的宿主机上使用localhost来访问ES了。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>vi config/elasticsearch.yml
network.host: 0.0.0.0
</code></pre>
</div>

<h3 id="section-5">2.3.启动</h3>

<div class="highlighter-rouge"><pre class="highlight"><code>/opt/elasticsearch/elasticsearch-2.3.4/bin/elasticsearch
</code></pre>
</div>

<h3 id="section-6">2.4.插件安装</h3>

<p>kopf插件安装：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>/opt/elasticsearch/elasticsearch-2.3.4/bin/plugin install lmenezes/elasticsearch-kopf
</code></pre>
</div>

<p>安装完之后，可以访问web页面http://[hostname]:9200/_plugin/kopf查看。</p>

<h3 id="section-7">2.5.验证</h3>

<p>es默认使用的9200端口，可使用下面的命令来查看该端口是否已经被监听：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>netstat -anp |grep :9200
</code></pre>
</div>

<p>或者使用浏览器访问端口9200.</p>

<h2 id="kibana">3. Kibana</h2>

<h3 id="section-8">3.1.下载</h3>
<p>https://www.elastic.co/downloads/kibana</p>

<h3 id="section-9">3.2.配置</h3>

<p>配置一下es的地址。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>vi config/kibana.yml

elasticsearch.url: "http://[hostname]:9200"
</code></pre>
</div>

<p>这里默认是使用ES的数据。</p>

<h3 id="section-10">3.3.启动</h3>

<div class="highlighter-rouge"><pre class="highlight"><code>/opt/kibana/kibana-4.5.3-linux-x64/bin/kibana
</code></pre>
</div>

<h3 id="section-11">3.4.验证</h3>

<p>访问：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>http://[hostname]:5601/
</code></pre>
</div>
<p>点击”create”创建索引名称。</p>

<h2 id="elk">4.使ELK整体协作起来</h2>

<h3 id="section-12">4.1.原理</h3>

<ul>
  <li>logstash</li>
</ul>

<p>logstash主要用作收集数据使用，可以自由的定义数据的入口和出口，兼容多种数据源。</p>

<ul>
  <li>elasticsearch</li>
</ul>

<p>es和solr比较类似，都是基于lucene的来提供的搜索服务。但是在高并发的表现上，ES的负载均衡效果是优于solr的。</p>

<ul>
  <li>kibana</li>
</ul>

<p>kibana是一个可以可以用来查看ES里数据的Web。在早期logstash有一个logstash-web，但是功能比较简单。咱们这里说的kibana严格意义上说是kibana4，是在2015年重构完成的一个版本。</p>

<h3 id="el">4.2.E和L的连接</h3>
<p>其实就是把logstash收集到的数据写入es中，这里只要在logstash的启动参数上做配置就可以了，具体的配置文件如下：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>vi logstash-indexer.conf

input {
  file {
    type =&gt;"syslog"
    path =&gt; [ "/var/log/syslog" ]
  }
  syslog {
    type =&gt;"syslog"
    port =&gt;"5544"
  }
}
output {
  stdout { codec=&gt; rubydebug }
  elasticsearch {hosts =&gt; "localhost" }
}
</code></pre>
</div>

<ul>
  <li>配置介绍</li>
</ul>

<p>logstash的配置里，一定要有一个input和一个output。
file: 这里配置输入的文件信息。
syslog：把logstash配置为一个可接收syslog服务器来接收file里变化的数据。
output里定义了两处输出，分别是<strong>stdout</strong>命令行和<strong>elasticsearch</strong>。</p>

<ul>
  <li>启动</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code>nohup ./logstash agent -f logstash-indexer.conf &gt; nohup &amp;
</code></pre>
</div>

<h3 id="kibana-1">4.3.Kibana的配置</h3>
<p>只需要修改kibana.yml中es的地址就可以了。</p>

<h3 id="es-1">4.4.ES</h3>
<p>ES在这个架构中作为数据存储和索引的系统。无额外的特殊配置。</p>

<h3 id="section-13">5.小结</h3>
<p>ELK架构在处理运维系统的日志分析以及一些数据量不是很大的场景还是很实用的。快速、简单、易扩展，企业中使用可以考虑使用hdfs作为es的数据存储来使用，具体性能需要根据实际的业务复杂度来衡量，复杂度不是很高的海量数据统计，可优先考虑使用elk方案。</p>

<p>参考地址：
http://baidu.blog.51cto.com/71938/1676798
https://www.gitbook.com/book/chenryn/kibana-guide-cn/details</p>


                </div>
                <div class="read-all">
                    <a  href="/2016/07/20/ELK%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E4%BB%8B%E7%BB%8D/"><i class="fa fa-newspaper-o"></i>Read All</a>
                </div>
                <hr>
              </li>
            
              <li>
                <h2>
                  <a class="post-link" href="/2016/05/17/Tez%E7%B3%BB%E5%88%97%E7%AC%AC%E4%B8%89%E7%AF%87-Tez%E5%92%8Coozie%E6%95%B4%E5%90%88/">Tez系列第三篇 Tez和oozie整合</a>
                </h2>
                <div class="label">
                    <div class="label-card">
                        <i class="fa fa-calendar"></i>2016-05-17
                    </div>
                    <div class="label-card">
                        
                    </div>
                    <div class="label-card">
                        
                    </div>

                    <div class="label-card">
                    


<!-- <span class="point">•</span> -->
<span class="categories">
  <i class="fa fa-th-list"></i>
  
    
        <a href="/category/#tez" title="Category: tez" rel="category">tez</a>
    
  

  <!-- <span class="point">•</span> -->
</span>


                    </div>

                    <div class="label-card">
                    
<!-- <span class="point">•</span> -->
<span class="pageTag">
  <i class="fa fa-tags"></i>
  
    
        <a href="/tag/#hadoop" title="Tag: hadoop" rel="tag">hadoop</a>&nbsp;
    
        <a href="/tag/#tez" title="Tag: tez" rel="tag">tez</a>&nbsp;
    
        <a href="/tag/#oozie" title="Tag: oozie" rel="tag">oozie</a>&nbsp;
    
        <a href="/tag/#hive" title="Tag: hive" rel="tag">hive</a>
    
  

</span>

                    </div>
                </div>
                <div class="excerpt">
                    <ul id="markdown-toc">
  <li><a href="#section" id="markdown-toc-section">1.完成上一篇的基础的相关配置</a></li>
  <li><a href="#tezjarooziehdfs" id="markdown-toc-tezjarooziehdfs">2.拷贝Tez的依赖Jar包到OOZIE的HDFS共享目录下</a></li>
  <li><a href="#jar" id="markdown-toc-jar">3.修改Jar的权限</a></li>
  <li><a href="#section-1" id="markdown-toc-section-1">4.是配置生效</a></li>
  <li><a href="#workflowtez" id="markdown-toc-workflowtez">5.在workflow里使用Tez</a>    <ul>
      <li><a href="#workflowhivetez" id="markdown-toc-workflowhivetez">5.1.使单个workflow里的hive都用tez</a></li>
      <li><a href="#workflowhivetez-1" id="markdown-toc-workflowhivetez-1">5.2.使单个workflow里的单个hive都用tez</a></li>
    </ul>
  </li>
</ul>

<h2 id="section">1.完成上一篇的基础的相关配置</h2>

<h2 id="tezjarooziehdfs">2.拷贝Tez的依赖Jar包到OOZIE的HDFS共享目录下</h2>
<div class="highlighter-rouge"><pre class="highlight"><code>hadoop fs -copyFromLocal *.jar /user/oozie/share/lib/lib_20150722203343/hive/
hadoop fs -copyFromLocal /usr/lib/tez/lib/*.jar /user/oozie/share/lib/lib_20150722203343/hive/
</code></pre>
</div>

<h2 id="jar">3.修改Jar的权限</h2>
<p>保证oozie有权限读取、使用Jar包:
<code class="highlighter-rouge">
hadoop fs -chown oozie:oozie /user/oozie/share/lib/lib_20150722203343/hive/*.jar
</code></p>

<h2 id="section-1">4.是配置生效</h2>
<div class="highlighter-rouge"><pre class="highlight"><code>oozie admin -sharelibupdate
oozie admin -shareliblist hive
</code></pre>
</div>
<p>或者重启oozie也可以</p>

<h2 id="workflowtez">5.在workflow里使用Tez</h2>
<p>这里咱们只是让oozie处理hive作业时使用Tez引擎，具体配置如下.</p>

<h3 id="workflowhivetez">5.1.使单个workflow里的hive都用tez</h3>
<p>在作业流的hive-site.xml中加入下面的配置，即可使整个作业里的hive都使用Tez引擎：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>&lt;property&gt;
	&lt;name&gt;hive.execution.engine&lt;/name&gt;
	&lt;value&gt;tez&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
	&lt;name&gt;tez.lib.uris&lt;/name&gt;
	&lt;value&gt;${nameNode}/tmp/apps/tez-0.8.2/,${nameNode}/tmp/apps/tez-0.8.2/lib&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
	&lt;name&gt;tez.use.cluster.hadoop-libs&lt;/name&gt;
	&lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
</code></pre>
</div>

<h3 id="workflowhivetez-1">5.2.使单个workflow里的单个hive都用tez</h3>
<p>上面的配置不用加，在workflow.xml里的hive节点添加如下配置:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>&lt;property&gt;
	&lt;name&gt;hive.execution.engine&lt;/name&gt;
	&lt;value&gt;tez&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
	&lt;name&gt;tez.lib.uris&lt;/name&gt;
	&lt;value&gt;${nameNode}/tmp/apps/tez-0.8.2/,${nameNode}/tmp/apps/tez-0.8.2/lib&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
	&lt;name&gt;tez.use.cluster.hadoop-libs&lt;/name&gt;
	&lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
</code></pre>
</div>

<p>hive.execution.engine属性可以不添加，在hive的脚本中的第一行添加:
<code class="highlighter-rouge">
set hive.execution.engine=tez;
</code></p>

                </div>
                <div class="read-all">
                    <a  href="/2016/05/17/Tez%E7%B3%BB%E5%88%97%E7%AC%AC%E4%B8%89%E7%AF%87-Tez%E5%92%8Coozie%E6%95%B4%E5%90%88/"><i class="fa fa-newspaper-o"></i>Read All</a>
                </div>
                <hr>
              </li>
            
              <li>
                <h2>
                  <a class="post-link" href="/2016/05/09/Tez%E7%B3%BB%E5%88%97%E7%AC%AC%E4%BA%8C%E7%AF%87-hive_on_tez/">Tez系列第二篇 Hive_on_tez</a>
                </h2>
                <div class="label">
                    <div class="label-card">
                        <i class="fa fa-calendar"></i>2016-05-09
                    </div>
                    <div class="label-card">
                        
                    </div>
                    <div class="label-card">
                        
                    </div>

                    <div class="label-card">
                    


<!-- <span class="point">•</span> -->
<span class="categories">
  <i class="fa fa-th-list"></i>
  
    
        <a href="/category/#tez" title="Category: tez" rel="category">tez</a>
    
  

  <!-- <span class="point">•</span> -->
</span>


                    </div>

                    <div class="label-card">
                    
<!-- <span class="point">•</span> -->
<span class="pageTag">
  <i class="fa fa-tags"></i>
  
    
        <a href="/tag/#hadoop" title="Tag: hadoop" rel="tag">hadoop</a>&nbsp;
    
        <a href="/tag/#tez" title="Tag: tez" rel="tag">tez</a>&nbsp;
    
        <a href="/tag/#hive" title="Tag: hive" rel="tag">hive</a>
    
  

</span>

                    </div>
                </div>
                <div class="excerpt">
                    <ul id="markdown-toc">
  <li><a href="#tez" id="markdown-toc-tez">1.安装配置Tez</a>    <ul>
      <li><a href="#section" id="markdown-toc-section">1.1.环境要求</a></li>
      <li><a href="#section-1" id="markdown-toc-section-1">1.2.集群准备</a></li>
      <li><a href="#section-2" id="markdown-toc-section-2">1.3. 编译环境准备</a></li>
      <li><a href="#nodejsnpm" id="markdown-toc-nodejsnpm">1.4. Nodejs、npm</a></li>
      <li><a href="#git" id="markdown-toc-git">1.5.安装GIT</a></li>
      <li><a href="#protocolbuffer250" id="markdown-toc-protocolbuffer250">1.6. ProtocolBuffer2.5.0</a></li>
      <li><a href="#tez-1" id="markdown-toc-tez-1">1.7.编译&amp;安装Tez</a></li>
    </ul>
  </li>
  <li><a href="#hivetez" id="markdown-toc-hivetez">2. 开始整合Hive和Tez</a>    <ul>
      <li><a href="#section-3" id="markdown-toc-section-3">2.1. 查看编译完成的目标目录结构</a></li>
      <li><a href="#tez-082-minimalhdfs" id="markdown-toc-tez-082-minimalhdfs">2.1. 拷贝tez-0.8.2-minimal目录至HDFS</a></li>
      <li><a href="#jar" id="markdown-toc-jar">2.2. 拷贝对应以来jar</a></li>
      <li><a href="#tez-082" id="markdown-toc-tez-082">2.3. 把tez-0.8.2拷贝到服务器本地部署的目录</a></li>
      <li><a href="#conftez-sitexml" id="markdown-toc-conftez-sitexml">2.4. 进入部署的目录创建conf/tez-site.xml</a></li>
      <li><a href="#tez-2" id="markdown-toc-tez-2">2.4. 把Tez加入到环境变量</a></li>
      <li><a href="#hivetez-1" id="markdown-toc-hivetez-1">2.5. 让Hive把Tez用起来</a></li>
    </ul>
  </li>
  <li><a href="#section-4" id="markdown-toc-section-4">常见的错误</a>    <ul>
      <li><a href="#sudotez" id="markdown-toc-sudotez">1.不要使用sudo权限来编译（编译tez时的错误）</a></li>
      <li><a href="#mavenfrontend-maven-plugintez" id="markdown-toc-mavenfrontend-maven-plugintez">2.maven插件frontend-maven-plugin的版本问题（编译tez时的错误）</a></li>
      <li><a href="#nodetez" id="markdown-toc-nodetez">3.解压Node压缩包时错误（编译tez时的错误）</a></li>
      <li><a href="#nodenpmtez" id="markdown-toc-nodenpmtez">4.node&amp;npm版本不对应（编译tez时的错误）</a></li>
      <li><a href="#mrerror-when-run-hive-on-tez" id="markdown-toc-mrerror-when-run-hive-on-tez">5.缺少MR的依赖包（error when run hive on tez）</a></li>
      <li><a href="#tezhive-on-oozie-" id="markdown-toc-tezhive-on-oozie-">6.tez&amp;hive on oozie 错误</a></li>
    </ul>
  </li>
</ul>

<h2 id="tez">1.安装配置Tez</h2>

<h3 id="section">1.1.环境要求</h3>

<ul>
  <li>CDH5.4.4(hadoop2.6.0)</li>
  <li>编译环境：gcc, gcc-c++, make, build</li>
  <li>Nodejs、npm (Tez-ui需要)</li>
  <li>Git</li>
  <li>pb2.5.0</li>
  <li>maven3</li>
  <li>Tez0.8.2</li>
</ul>

<h3 id="section-1">1.2.集群准备</h3>
<p>以及安装完成的cdh5.4.4集群。</p>

<h3 id="section-2">1.3. 编译环境准备</h3>
<p>安装gcc, gcc-c++, make, build  <br />
<code class="highlighter-rouge">
yum install gcc gcc-c++ libstdc++-devel make build
</code></p>

<h3 id="nodejsnpm">1.4. Nodejs、npm</h3>
<p>下载源码:  <br />
<code class="highlighter-rouge">
wget http://nodejs.org/dist/v0.8.14/node-v0.8.14.tar.gz
</code></p>

<p>解压后编译:  <br />
<code class="highlighter-rouge">
./configure
make &amp;&amp; make install
</code></p>

<p>查看nodejs和npm的版本:  <br />
<code class="highlighter-rouge">
node --version
npm --version
</code></p>

<p>笔者的安装环境里，node的版本是v0.12.9，npm的版本是2.14.9</p>

<h3 id="git">1.5.安装GIT</h3>
<p>下载git:  <br />
<code class="highlighter-rouge">
https://git-scm.com/download    
笔者选择的是1.7.3版本
</code></p>

<p>解压后编译:  <br />
<code class="highlighter-rouge">
./configure
make
make install
</code></p>

<h3 id="protocolbuffer250">1.6. ProtocolBuffer2.5.0</h3>
<ul>
  <li>下载pb源码  <br />
<code class="highlighter-rouge">
https://github.com/google/protobuf/releases/tag/v2.5.0
</code></li>
  <li>
    <p>编译安装pb  <br />
<code class="highlighter-rouge">
./configure -prefix=/opt/protoc/
make &amp;&amp; make install
</code></p>
  </li>
  <li>配置环境变量 <br />
<code class="highlighter-rouge">
export PROTOC_HOME=/opt/protoc
export PATH=$PATH:$PROTOC_HOME/bin
</code></li>
  <li>检验  <br />
<code class="highlighter-rouge">
protoc --version
</code>  <br />
查看pb的版本是不是2.5.0，笔者这里显示为 <strong>libprotoc 2.5.0</strong></li>
</ul>

<h3 id="tez-1">1.7.编译&amp;安装Tez</h3>
<ul>
  <li>下载Tez <br />
Tez所有版本列表在者：</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code>http://tez.apache.org/releases/index.html
</code></pre>
</div>
<p>笔者这里下载的是0.8.2版本。</p>

<ul>
  <li>解压修改配置</li>
</ul>

<p>vi pom.xml</p>

<div class="highlighter-rouge"><pre class="highlight"><code>&lt;hadoop.version&gt;2.6.0-cdh5.4.4&lt;/hadoop.version&gt;
</code></pre>
</div>

<p>vi tez-ui/pom.xml</p>

<div class="highlighter-rouge"><pre class="highlight"><code>&lt;nodeVersion&gt;v0.12.9&lt;/nodeVersion&gt;
&lt;npmVersion&gt;2.14.9&lt;/npmVersion&gt;
</code></pre>
</div>

<ul>
  <li>开始编译</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code>mvn clean package -DskipTests=true -Dmaven.javadoc.skip=true  -Dfrontend-maven-plugin.version=0.0.23
</code></pre>
</div>

<blockquote>
  <p>编译的过程中可能会发生错误，我这边由于网络故障，经常会出现node.gz.tar文件下载失败。最后还是编译成功了。</p>
</blockquote>

<h2 id="hivetez">2. 开始整合Hive和Tez</h2>

<h3 id="section-3">2.1. 查看编译完成的目标目录结构</h3>
<div class="highlighter-rouge"><pre class="highlight"><code>[wulin@lf-R710-29 target]$ ls
archive-tmp  maven-archiver  tez-0.8.2  tez-0.8.2-minimal  tez-0.8.2-minimal.tar.gz  tez-0.8.2.tar.gz  tez-dist-0.8.2-tests.jar
</code></pre>
</div>

<h3 id="tez-082-minimalhdfs">2.1. 拷贝tez-0.8.2-minimal目录至HDFS</h3>
<div class="highlighter-rouge"><pre class="highlight"><code>hdfs dfs -put tez-0.8.2-minimal /tmp/tez-dir/
</code></pre>
</div>
<p>先拷贝到tmp目录做测试，成功运行后在拷贝到正式目录。</p>

<h3 id="jar">2.2. 拷贝对应以来jar</h3>
<p>把hadoop-mapreduce-client-common-2.6.0-cdh5.4.4.jar到hdfs的/tmp/tez-dir/tez-0.8.2-minimal目录</p>

<h3 id="tez-082">2.3. 把tez-0.8.2拷贝到服务器本地部署的目录</h3>
<div class="highlighter-rouge"><pre class="highlight"><code>cp -r tez-0.8.2 /opt/
</code></pre>
</div>

<h3 id="conftez-sitexml">2.4. 进入部署的目录创建conf/tez-site.xml</h3>
<div class="highlighter-rouge"><pre class="highlight"><code><span class="cp">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span>
<span class="cp">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span>
<span class="nt">&lt;configuration&gt;</span>
 <span class="nt">&lt;property&gt;</span>
   <span class="nt">&lt;name&gt;</span>tez.lib.uris<span class="nt">&lt;/name&gt;</span>
   <span class="nt">&lt;value&gt;</span>${fs.defaultFS}/tmp/tez-dir/tez-0.8.2-minimal,${fs.defaultFS}/tmp/tez-dir/tez-0.8.2-minimal/lib<span class="nt">&lt;/value&gt;</span>
 <span class="nt">&lt;/property&gt;</span>
 <span class="nt">&lt;property&gt;</span>
   <span class="nt">&lt;name&gt;</span>tez.use.cluster.hadoop-libs<span class="nt">&lt;/name&gt;</span>
   <span class="nt">&lt;value&gt;</span>true<span class="nt">&lt;/value&gt;</span>
 <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span>
</code></pre>
</div>
<blockquote>
  <p>注：tez.lib.uris参数值，是之前上传到hdfs目录的tez包，它必须是tez-0.8.2-minimal目录，而不能是tez-0.8.2目录。（如果有谁使用tez-0.8.2目录部署成功的话，可以告诉我，谢谢！）。根据官网的说明，使用tez-0.8.2-minimal包的时候，务必设置tez.use.cluster.hadoop-libs属性为true。</p>
</blockquote>

<h3 id="tez-2">2.4. 把Tez加入到环境变量</h3>

<div class="highlighter-rouge"><pre class="highlight"><code>export TEZ_JARS=/opt/tez-0.8.2-minimal
export TEZ_CONF_DIR=$TEZ_JARS/conf
export HADOOP_CLASSPATH=${TEZ_CONF_DIR}:${TEZ_JARS}/*:${TEZ_JARS}/lib/*
</code></pre>
</div>
<blockquote>
  <p>注：经笔者的测试，TEZ_JARS指向tez-0.8.2-minimal目录或者tez-0.8.2目录都是可以的。</p>
</blockquote>

<h3 id="hivetez-1">2.5. 让Hive把Tez用起来</h3>
<ul>
  <li>配置整合
临时配置</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code>hive&gt;set hive.execution.engine=tez;
</code></pre>
</div>
<p>或者修改hive-site.xml（长期配置）</p>

<div class="highlighter-rouge"><pre class="highlight"><code> &lt;property&gt;
   &lt;name&gt;hive.execution.engine&lt;/name&gt;
   &lt;value&gt;tez&lt;/value&gt;
 &lt;/property&gt;
</code></pre>
</div>
<ul>
  <li>执行hive，验证查看</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code>hive&gt; select count(*) from dual;
Query ID = wulin_20160406152121_6fd704e7-a437-4345-9958-2fbd1cccb057
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=&lt;number&gt;
In order to set a constant number of reducers:
  set mapreduce.job.reduces=&lt;number&gt;
Starting Job = job_1457012272029_352465, Tracking URL = http://lfh-R710-165:8088/proxy/application_1457012272029_352465/
Kill Command = /opt/cloudera/parcels/CDH-5.4.4-1.cdh5.4.4.p0.4/lib/hadoop/bin/hadoop job  -kill job_1457012272029_352465
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2016-04-06 15:21:29,925 Stage-1 map = 0%,  reduce = 0%
2016-04-06 15:21:38,274 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.05 sec
2016-04-06 15:21:45,611 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.86 sec
MapReduce Total cumulative CPU time: 3 seconds 860 msec
Ended Job = job_1457012272029_352465
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 3.86 sec   HDFS Read: 6138 HDFS Write: 2 SUCCESS
Total MapReduce CPU Time Spent: 3 seconds 860 msec
OK
1
Time taken: 35.934 seconds, Fetched: 1 row(s)
hive&gt; set hive.execution.engine=tez;
hive&gt; select count(*) from dual;
Query ID = wulin_20160406152222_426dd505-1f6a-4d02-ae95-5a4d0e6bbc76
Total jobs = 1
Launching Job 1 out of 1
Status: Running (Executing on YARN cluster with App id application_1457012272029_352467)
--------------------------------------------------------------------------------
        VERTICES      STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED  KILLED
--------------------------------------------------------------------------------
Map 1 ..........   SUCCEEDED      1          1        0        0       0       0
Reducer 2 ......   SUCCEEDED      1          1        0        0       0       0
--------------------------------------------------------------------------------
VERTICES: 02/02  [==========================&gt;&gt;] 100%  ELAPSED TIME: 9.64 s     
--------------------------------------------------------------------------------
OK
1
Time taken: 22.211 seconds, Fetched: 1 row(s)
hive&gt; 
</code></pre>
</div>
<p>如下图：
<img src="http://7xriy2.com1.z0.glb.clouddn.com/tez-ok.png" alt="Hive on Tez" title="Hive on Tez" /></p>

<p>到此，hive on tez，整合完毕！</p>

<h2 id="section-4">常见的错误</h2>

<h3 id="sudotez">1.不要使用sudo权限来编译（编译tez时的错误）</h3>
<div class="highlighter-rouge"><pre class="highlight"><code>[ERROR] Failed to execute goal org.codehaus.mojo:exec-maven-plugin:1.3.2:exec (Bower install) on project tez-ui: Command execution failed. Process exited with an error: 1 (Exit value: 1) -&gt; [Help 1]
</code></pre>
</div>
<p>解决办法：
不要使用root用户，也不要使用sudo来编译.</p>

<h3 id="mavenfrontend-maven-plugintez">2.maven插件frontend-maven-plugin的版本问题（编译tez时的错误）</h3>

<div class="highlighter-rouge"><pre class="highlight"><code>[ERROR] Failed to execute goal com.github.eirslett:frontend-maven-plugin:0.0.22:install-node-and-npm (install node and npm) on project tez-ui: Execution install node and npm of goal com.github.eirslett:frontend-maven-plugin:0.0.22:install-node-and-npm failed: A required class was missing while executing com.github.eirslett:frontend-maven-plugin:0.0.22:install-node-and-npm: org/slf4j/helpers/MarkerIgnoringBase
</code></pre>
</div>
<p>解决办法：强制执行编译时frontend-maven-plugin插件的版本（mvn clean package -DskipTests=true -Dmaven.javadoc.skip=true  -Dfrontend-maven-plugin.version=0.0.XX）
如果maven的版本低于3.1，frontend-maven-plugin版本应该 &lt;= 0.0.22；
如果maven的版本大于或等于3.1，frontend-maven-plugin版本应该 &gt;= 0.0.23.</p>

<h3 id="nodetez">3.解压Node压缩包时错误（编译tez时的错误）</h3>

<div class="highlighter-rouge"><pre class="highlight"><code>[ERROR] Failed to execute goal com.github.eirslett:frontend-maven-plugin:0.0.22:install-node-and-npm (install node and npm) on project tez-ui: Could not extract the Node archive: Could not extract archive: '/home/.../tez/tez-ui/src/main/webapp/node_tmp/node.tar.gz': EOFException -&gt; [Help 1]
</code></pre>
</div>
<p>解决版本：检查第二个问题，并重新执行。如果还失败，可以多执行几次，可能和网络有关系。</p>

<h3 id="nodenpmtez">4.node&amp;npm版本不对应（编译tez时的错误）</h3>

<div class="highlighter-rouge"><pre class="highlight"><code>[ERROR] npm WARN engine hoek@2.16.3: wanted: {"node":"&gt;=0.10.40"} (current: {"node":"v0.10.18","npm":"1.3.8"})
[ERROR] npm WARN engine boom@2.10.1: wanted: {"node":"&gt;=0.10.40"} (current: {"node":"v0.10.18","npm":"1.3.8"})
[ERROR] npm WARN engine cryptiles@2.0.5: wanted: {"node":"&gt;=0.10.40"} (current: {"node":"v0.10.18","npm":"1.3.8"})
</code></pre>
</div>
<p>解决办法：
1. 安装正确版本的nodeJs；
2. 修改tez-ui/pom.xml中的nodeVersion和npmVersion标签值为系统环境的值。可使用下面命令，查看系统里的node和npm版本：
<code class="highlighter-rouge">
node --version
npm --version
</code></p>

<h3 id="mrerror-when-run-hive-on-tez">5.缺少MR的依赖包（error when run hive on tez）</h3>
<div class="highlighter-rouge"><pre class="highlight"><code>Vertex failed, vertexName=Map 1, vertexId=vertex_1457012272029_352429_1_00, diagnostics=[Vertex vertex_1457012272029_352429_1_00 [Map 1] killed/failed due to:ROOT_INPUT_INIT_FAILURE, Vertex Input: dual initializer failed, vertex=vertex_1457012272029_352429_1_00 [Map 1], java.lang.NoClassDefFoundError: org/apache/hadoop/mapred/MRVersion
        at org.apache.hadoop.hive.shims.Hadoop23Shims.isMR2(Hadoop23Shims.java:843)
        at org.apache.hadoop.hive.shims.Hadoop23Shims.getHadoopConfNames(Hadoop23Shims.java:914)
        at org.apache.hadoop.hive.conf.HiveConf$ConfVars.&lt;clinit&gt;(HiveConf.java:356)
        at org.apache.hadoop.hive.ql.exec.Utilities.getBaseWork(Utilities.java:371)
        at org.apache.hadoop.hive.ql.exec.Utilities.getMapWork(Utilities.java:296)
        at org.apache.hadoop.hive.ql.exec.tez.HiveSplitGenerator.initialize(HiveSplitGenerator.java:106)
        at org.apache.tez.dag.app.dag.RootInputInitializerManager$InputInitializerCallable$1.run(RootInputInitializerManager.java:278)
        at org.apache.tez.dag.app.dag.RootInputInitializerManager$InputInitializerCallable$1.run(RootInputInitializerManager.java:269)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:415)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
        at org.apache.tez.dag.app.dag.RootInputInitializerManager$InputInitializerCallable.call(RootInputInitializerManager.java:269)
        at org.apache.tez.dag.app.dag.RootInputInitializerManager$InputInitializerCallable.call(RootInputInitializerManager.java:253)
        at java.util.concurrent.FutureTask.run(FutureTask.java:262)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.mapred.MRVersion
        at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
        at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
        ... 17 more
]
Vertex killed, vertexName=Reducer 2, vertexId=vertex_1457012272029_352429_1_01, diagnostics=[Vertex received Kill in INITED state., Vertex vertex_1457012272029_352429_1_01 [Reducer 2] killed/failed due to:OTHER_VERTEX_FAILURE]
DAG did not succeed due to VERTEX_FAILURE. failedVertices:1 killedVertices:1
FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.tez.TezTask
</code></pre>
</div>
<p>这个错误是在配置完之后，运行hive时才会出现的。
解决办法：
拷贝mr依赖包至tez的hdfs目录中。笔者的环境是CDH5.4.4，所以把hadoop-mapreduce-client-common-2.6.0-cdh5.4.4.jar拷贝到hdfs的/tmp/tez-dir/tez-0.8.2-minimal目录，就解决问题了。</p>

<h3 id="tezhive-on-oozie-">6.tez&amp;hive on oozie 错误</h3>

<div class="highlighter-rouge"><pre class="highlight"><code>Status: Running (Executing on YARN cluster with App id application_1461470184587_0770)

Map 1: -/-	Reducer 2: 0/1	
Status: Failed
Vertex failed, vertexName=Map 1, vertexId=vertex_1461470184587_0770_1_00, diagnostics=[Vertex vertex_1461470184587_0770_1_00 [Map 1] killed/failed due to:ROOT_INPUT_INIT_FAILURE, Vertex Input: wl_manager_core_assembly initializer failed, vertex=vertex_1461470184587_0770_1_00 [Map 1], java.lang.IllegalArgumentException: Illegal Capacity: -1
	at java.util.ArrayList.&lt;init&gt;(ArrayList.java:142)
	at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:330)
	at org.apache.hadoop.hive.ql.io.HiveInputFormat.addSplitsForGroup(HiveInputFormat.java:306)
	at org.apache.hadoop.hive.ql.io.HiveInputFormat.getSplits(HiveInputFormat.java:408)
	at org.apache.hadoop.hive.ql.exec.tez.HiveSplitGenerator.initialize(HiveSplitGenerator.java:129)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager$InputInitializerCallable$1.run(RootInputInitializerManager.java:278)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager$InputInitializerCallable$1.run(RootInputInitializerManager.java:269)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1671)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager$InputInitializerCallable.call(RootInputInitializerManager.java:269)
	at org.apache.tez.dag.app.dag.RootInputInitializerManager$InputInitializerCallable.call(RootInputInitializerManager.java:253)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
]
Vertex killed, vertexName=Reducer 2, vertexId=vertex_1461470184587_0770_1_01, diagnostics=[Vertex received Kill in INITED state., Vertex vertex_1461470184587_0770_1_01 [Reducer 2] killed/failed due to:OTHER_VERTEX_FAILURE]
DAG did not succeed due to VERTEX_FAILURE. failedVertices:1 killedVertices:1
FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.tez.TezTask
Intercepting System.exit(2)
Failing Oozie Launcher, Main class [org.apache.oozie.action.hadoop.HiveMain], exit code [2]
</code></pre>
</div>

<p>参考链接：
http://m.oschina.net/blog/421764  <br />
http://duguyiren3476.iteye.com/blog/2214549
https://cwiki.apache.org/confluence/display/TEZ/Build+errors+and+solutions</p>


                </div>
                <div class="read-all">
                    <a  href="/2016/05/09/Tez%E7%B3%BB%E5%88%97%E7%AC%AC%E4%BA%8C%E7%AF%87-hive_on_tez/"><i class="fa fa-newspaper-o"></i>Read All</a>
                </div>
                <hr>
              </li>
            
              <li>
                <h2>
                  <a class="post-link" href="/2016/04/01/Tez%E7%B3%BB%E5%88%97%E7%AC%AC%E4%B8%80%E7%AF%87-%E5%9F%BA%E7%A1%80%E5%B8%B8%E8%AF%86/">Tez系列第一篇 基础常识</a>
                </h2>
                <div class="label">
                    <div class="label-card">
                        <i class="fa fa-calendar"></i>2016-04-01
                    </div>
                    <div class="label-card">
                        
                    </div>
                    <div class="label-card">
                        
                    </div>

                    <div class="label-card">
                    


<!-- <span class="point">•</span> -->
<span class="categories">
  <i class="fa fa-th-list"></i>
  
    
        <a href="/category/#tez" title="Category: tez" rel="category">tez</a>
    
  

  <!-- <span class="point">•</span> -->
</span>


                    </div>

                    <div class="label-card">
                    
<!-- <span class="point">•</span> -->
<span class="pageTag">
  <i class="fa fa-tags"></i>
  
    
        <a href="/tag/#hadoop" title="Tag: hadoop" rel="tag">hadoop</a>&nbsp;
    
        <a href="/tag/#tez" title="Tag: tez" rel="tag">tez</a>
    
  

</span>

                    </div>
                </div>
                <div class="excerpt">
                    <ul id="markdown-toc">
  <li><a href="#tez" id="markdown-toc-tez">1.Tez是什么</a>    <ul>
      <li><a href="#section" id="markdown-toc-section">1.1.介绍</a></li>
      <li><a href="#section-1" id="markdown-toc-section-1">1.2.两大优势</a></li>
    </ul>
  </li>
  <li><a href="#tez-1" id="markdown-toc-tez-1">2.为什么要有Tez</a>    <ul>
      <li><a href="#yarnam" id="markdown-toc-yarnam">2.1.YARN的AM</a></li>
      <li><a href="#yarn" id="markdown-toc-yarn">2.2.YARN的资源无法重用</a></li>
      <li><a href="#yarndag" id="markdown-toc-yarndag">2.3.YARN的DAG中间计算结果读写效率低下</a></li>
    </ul>
  </li>
  <li><a href="#tez-2" id="markdown-toc-tez-2">3.Tez能解决什么问题</a>    <ul>
      <li><a href="#amamampoolserver" id="markdown-toc-amamampoolserver">3.1.使用AM缓冲池实现AM的复用，AMPoolServer</a></li>
      <li><a href="#container" id="markdown-toc-container">3.2.Container预启动</a></li>
      <li><a href="#container-1" id="markdown-toc-container-1">3.3.Container重用</a></li>
    </ul>
  </li>
</ul>

<p>本文主要围绕着这么几个问题来展开：Tez是什么？为什么要有Tez？Tez能解决什么问题？</p>

<h2 id="tez">1.Tez是什么</h2>

<h3 id="section">1.1.介绍</h3>
<p>Tez目标是用来构建复杂的有向五环图数据处理程序。Tez项目目前是构建在YARN之上的。详情可以查看Tez的官网：http://tez.apache.org/</p>

<h3 id="section-1">1.2.两大优势</h3>
<p><strong>用户体验</strong>  <br />
- 使用API来自定义数据流  <br />
- 灵活的Input-Processor-Output运行模式  <br />
- 与计算的数据类型无关  <br />
- 简单的部署流程</p>

<p><strong>计算性能</strong>  <br />
- 性能高于MapReduce  <br />
- 资源管理更加优化  <br />
- 运行时配置预加载  <br />
- 物理数据流动态运行</p>

<p><strong>举例</strong>  <br />
下图是一个基于MR的Hive/Pig的DAG数据流处理过程:  <br />
<img src="http://7xriy2.com1.z0.glb.clouddn.com/tez01-PigHiveQueryOnMR.png" alt="Hive/Pig" title="Hive/Pig的DAG" /></p>

<p>下图是一个基于Tez的Hive/Pig的DAG数据流处理过程:  <br />
<img src="http://7xriy2.com1.z0.glb.clouddn.com/tez02-PigHiveQueryOnTez.png" alt="Hive/Pig" title="Hive/Pig的DAG" /></p>

<h2 id="tez-1">2.为什么要有Tez</h2>

<h3 id="yarnam">2.1.YARN的AM</h3>

<p>YARN的每个作业在执行前都会先创建一个AM，然后才会开始正真的计算。这样处理小作业的时候，会有较大的延迟，而且还会造成极大的性能浪费。</p>

<h3 id="yarn">2.2.YARN的资源无法重用</h3>
<p>在MR1中，用户可以开启JVM重用，用来降低作业延迟。
但是在YARN中，每个作业的AM会先向RM申请资源（Container），申请到资源之后开始运行作业，作业处理完成后释放资源，期间没有资源重新利用的环节。这样会使作业大大的延迟。</p>

<h3 id="yarndag">2.3.YARN的DAG中间计算结果读写效率低下</h3>
<p>可以查看1.2中的图“<strong>基于MR的Hive/Pig的DAG数据流处理过程</strong>”，可以看出图中的每一节点都是把结果写到一个中间存储（HDFS/S3）中，下个节点从中间存储读取数据，再来继续接下来的计算。可见中间存储的读写性能对整个DAG的性能影响是很大的。  <br />
如果使用Tez，则可以省去中间存储的读写，上个节点的输出可以直接重定向到下个节点的输入。</p>

<h2 id="tez-2">3.Tez能解决什么问题</h2>

<h3 id="amamampoolserver">3.1.使用AM缓冲池实现AM的复用，AMPoolServer</h3>

<p>使用Tez后，yarn的作业不是先提交给RM了，而是提交给AMPS。AMPS在启动后，会预先创建若干个AM，作为AM资源池，当作业被提交到AMPS的时候，AMPS会把该作业直接提交到AM上，这样就避免每个作业都创建独立的AM，大大的提高了效率。</p>

<h3 id="container">3.2.Container预启动</h3>
<p>AM缓冲池中的每个AM在启动时都会预先创建若干个container，以此来减少因创建container所话费的时间。</p>

<h3 id="container-1">3.3.Container重用</h3>
<p>每个任务运行完之后，AM不会立马释放Container，而是将它分配给其它未执行的任务。  <br />
看到这里， Tez是什么？为什么要有Tez？Tez能解决什么问题？应该都知道了吧！下一篇来开始讲解正式环境中的使用。</p>


                </div>
                <div class="read-all">
                    <a  href="/2016/04/01/Tez%E7%B3%BB%E5%88%97%E7%AC%AC%E4%B8%80%E7%AF%87-%E5%9F%BA%E7%A1%80%E5%B8%B8%E8%AF%86/"><i class="fa fa-newspaper-o"></i>Read All</a>
                </div>
                <hr>
              </li>
            
        </ul>



        <!-- Pagination links -->
        <div class="pagination">
          
            <span class="previous disable"><i class="fa fa-angle-double-left"></i></span>
            <span class="previous disable"><i class="fa fa-angle-left"></i></span>
          
          <span class="page_number ">1/2</span>
          
            <a href="/page2" class="next"><i class="fa fa-angle-right"></i></a>
            <a href="/page2" class="next"><i class="fa fa-angle-double-right"></i></a>
          
        </div>
    </div>
    <!-- <button class="anchor"><i class="fa fa-anchor"></i></button> -->
    <div class="right">
        <div class="wrap">
            <div class="side">
                <div>
                    <i class="fa fa-pencil-square-o" aria-hidden="true"></i>
                    Recent Posts
                </div>
                <ul class="content-ul" recent>
                    
                        <li><a href="/2016/07/23/%E4%BD%BF%E7%94%A8CM%E5%AE%89%E8%A3%85CDH%E5%8F%91%E8%A1%8C%E7%89%88%E7%9A%84Hadoop%E9%9B%86%E7%BE%A4/">使用cm安装cdh发行版的hadoop集群</a></li>
                    
                        <li><a href="/2016/07/20/ELK%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E4%BB%8B%E7%BB%8D/">Elk安装配置介绍</a></li>
                    
                        <li><a href="/2016/05/17/Tez%E7%B3%BB%E5%88%97%E7%AC%AC%E4%B8%89%E7%AF%87-Tez%E5%92%8Coozie%E6%95%B4%E5%90%88/">Tez系列第三篇 Tez和oozie整合</a></li>
                    
                        <li><a href="/2016/05/09/Tez%E7%B3%BB%E5%88%97%E7%AC%AC%E4%BA%8C%E7%AF%87-hive_on_tez/">Tez系列第二篇 Hive_on_tez</a></li>
                    
                        <li><a href="/2016/04/01/Tez%E7%B3%BB%E5%88%97%E7%AC%AC%E4%B8%80%E7%AF%87-%E5%9F%BA%E7%A1%80%E5%B8%B8%E8%AF%86/">Tez系列第一篇 基础常识</a></li>
                    
                        <li><a href="/2016/03/13/hadoop%E4%BC%98%E5%8C%96-yarn/">Hadoop优化 Yarn</a></li>
                    
                        <li><a href="/2015/02/23/hadoop%E4%BC%98%E5%8C%96-%E6%A6%82%E8%BF%B0/">Hadoop优化 概述</a></li>
                    
                        <li><a href="/2014/05/28/tomcat6%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE/">Tomcat6集群配置</a></li>
                    
                        <li><a href="/2014/05/15/ubuntu%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE/">Ubuntu常用配置</a></li>
                    
                </ul>
            </div>

            <!-- Content -->
            <div class="side ">
                <div>
                    <i class="fa fa-th-list"></i>
                    Categories
                </div>
                <ul class="content-ul" cate>
                    
                    <li>
                        <a href="/category/#linux" class="categories-list-item" cate="linux">
                            <span class="name">
                                linux
                            </span>
                            <span class="badge">1</span>
                        </a>
                    </li>
                    
                    <li>
                        <a href="/category/#WebService" class="categories-list-item" cate="WebService">
                            <span class="name">
                                WebService
                            </span>
                            <span class="badge">1</span>
                        </a>
                    </li>
                    
                    <li>
                        <a href="/category/#hadoop" class="categories-list-item" cate="hadoop">
                            <span class="name">
                                hadoop
                            </span>
                            <span class="badge">3</span>
                        </a>
                    </li>
                    
                    <li>
                        <a href="/category/#tez" class="categories-list-item" cate="tez">
                            <span class="name">
                                tez
                            </span>
                            <span class="badge">3</span>
                        </a>
                    </li>
                    
                    <li>
                        <a href="/category/#ELK" class="categories-list-item" cate="ELK">
                            <span class="name">
                                ELK
                            </span>
                            <span class="badge">1</span>
                        </a>
                    </li>
                    
                </ul>
            </div>
            <!-- 其他div框放到这里 -->
            <div class="side">
                <div>
                    <i class="fa fa-tags"></i>
                    Tags
                </div>
                <div class="tags-cloud">
                    
                    
                    
                    
                    

                    
                      
                      
                      
                      
                      
                      <a href="/tag/#ubuntu" style="font-size: 9pt; color: #999;">ubuntu</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#tomcat" style="font-size: 9pt; color: #999;">tomcat</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#集群优化" style="font-size: 11.5pt; color: #777;">集群优化</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#hadoop" style="font-size: 18pt; color: #000;">hadoop</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#tez" style="font-size: 13.5pt; color: #444;">tez</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#hive" style="font-size: 11.5pt; color: #777;">hive</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#oozie" style="font-size: 9pt; color: #999;">oozie</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#es" style="font-size: 9pt; color: #999;">es</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#logstash" style="font-size: 9pt; color: #999;">logstash</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#kibana" style="font-size: 9pt; color: #999;">kibana</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#ELK" style="font-size: 9pt; color: #999;">ELK</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#cm" style="font-size: 9pt; color: #999;">cm</a>
                    
                </div>
            </div>

            <!-- <div class="side">
                <div>
                    <i class="fa fa-external-link"></i>
                    Links
                </div>
                <ul  class="content-ul">

                </ul>
            </div> -->
        </div>
    </div>
</div>
<!-- <script src="/js/scroll.min.js " charset="utf-8"></script> -->
<!-- <script src="/js/pageContent.js " charset="utf-8"></script> -->


    <footer class="site-footer">


  <div class="wrapper">
      <p class="description">
          
          小鸟的成长记录.
          
      </p>
        <p class="contact">
            Contact me at:
            
            <a href="https://github.com/leocook"><i class="fa fa-github" aria-hidden="true"></i></a>
            

            
            <a href="mailto:leocook@163.com"><i class="fa fa-envelope-o" aria-hidden="true"></i></a>
            

            
            <a href="http://weibo.com/wulinjq"><i class="fa fa-weibo" aria-hidden="true"></i></a>
            

            

            

            
        </p>
        <p class="power">
            <span>
                Site powered by <a href="https://jekyllrb.com/">Jekyll</a> & <a href="https://pages.github.com/">Github Pages</a>.
            </span>
            <span>
                Theme designed by <a href="https://github.com/Gaohaoyang">HyG</a>.
            </span>
        </p>

  </div>
</footer>
<script src="/js/main.js " charset="utf-8"></script>


  </body>

</html>
